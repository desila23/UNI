Riprendiamo il discorso dell'ultima lezione sulla correlazione polinomiale.
Prendi questo esempio
![[Pasted image 20250424164625.png]]
Vedi che posso andare avanti all'infinito.

Ma nella teoria della Complessit√† Computazionale le cose non sono proprio cos√¨.

---

## Alla ricerca della macchina pi√π veloce
#### Teorema per `dtime`
>[!lemma] Teorema 6.7 - Accelerazione lineare
>![[Pasted image 20250424165016.png]]

Questo teorema ci dice che, dato un qualunque algoritmo, ne esiste sempre uno pi√π veloce (di un fattore costante!).

>[!question] Perch√© per√≤ abbiamo i due addendi $O(|x|^{2})$ e $O(|x|)$?
>Perch√© per essere pi√π efficienti, gli algoritmi devono
>- codificare in forma espressa il proprio input (vedi teorema successivo)
>	- se la codifica √® scritta su un nastro apposito ($T_{2}$) allora bastano $O(|x|)$ passi
>	- se la macchia dispone di un solo nastro ($T_{1}$) allora occorrono $O(|x|^{2})$ passi

#### Teorema per `dspace`
Dimostriamo un teorema analogo a quello di prima ma per `dspace`
>[!lemma] Teorema 6.6 - Compressione lineare
>![[Pasted image 20250424170459.png]]

Anche qui, viene detto che, dato un qualunque algoritmo, ne esiste un altro che usa una frazione costante della memoria del primo

>[!question] Perch√© l'addendo $O(|x|)$?
>Intanto, l'input di $T_{1}$ √® lo stesso di $T$.
>Pertanto $T_{1}$ deve codificare in forma compressa il proprio input e poi lavorare sull'alfabeto compresso.
>
>Osserva come l'alfabeto compresso sia $\Sigma^{k}$ (ossia, un carattere dell‚Äôalfabeto compresso √® una parola di k caratteri di Œ£) e che l'alfabeto di $T_{1}$ √® $$\Sigma^{k} \cup \Sigma$$perch√© l'alfabeto originale non scompare.


---

## Classi di complessit√† (deterministiche)
Siamo pronti a raggruppare i linguaggi in base all'efficienza delle macchine che li decidono.

>[!question] Cosa vuol dire che una macchina che decide un linguaggio ha una certa efficienza?
>Significa che la macchina che decide un linguaggio $L \subseteq \Sigma^{*}$ si comporti "bene" su <u>ogni</u> parola $x \in \Sigma^{*}$

Per√≤ ovviamente non possiamo trovare la macchina "migliore", perch√© tanto sappiamo che se ne prendo una ne esisteranno altre pi√π potenti (teoremi di prima).

Per risolvere questa questione utilizziamo la notazione $O$ e diciamo che 
	==Un linguaggio `L` appartiene all'insieme caratterizzato dalla "efficienza temporale" individuata dalla funzione totale e calcolabile `f`, se esiste una macchina `T` che decide (o accetta) `L` e che, per ogni `x` sull'alfabeto di `L`, termina in `O(f(|x|))` istruzioni.==

E discorso analogo per "efficienza spaziale".

#### Effettive classi di complessit√† deterministiche
##### Efficienza temporale - DTIME
Le classi che misurano "efficienza temporale" nel caso deterministico si chiamano <font color="#ff0000">DTIME</font>: data una <font color="#245bdb">funzione totale e calcolabile f</font> ![[Pasted image 20250424182246.png]]
ATTENZIONE:  ^460bf9
- <font color="#245bdb">dtime</font> (minuscolo) √® la **misura di complessit√†**, ossia, una <u>funzione</u>
- <font color="#ff0000">DTIME</font> (MAIUSCOLO) √® una **classe di complessit√†**, ossia, un <u>insieme</u>

##### Efficienza spaziale - DSPACE
Le classi che misurano "efficienza spaziale" nel caso deterministico si chiamano <font color="#ff0000">DSPACE</font>: data una <font color="#245bdb">funzione totale e calcolabile f</font> ![[Pasted image 20250424182520.png]]


---

## Classi di complessit√† (non deterministiche)
Facciamo le stesse considerazioni delle deterministiche.
##### Efficienza temporale - NTIME
Le classi che misurano "efficienza temporale" nel caso non deterministico si chiamano <font color="#ff0000">NTIME</font>: data una <font color="#245bdb">funzione totale e calcolabile f</font> ![[Pasted image 20250424182637.png]]
Qui si parla di ACCETTAZIONE perch√© sappiamo che se un linguaggio √® accettato entro un certo numero di istruzioni, sappiamo che √® decidibile; <u>MA NON SAPPIAMO QUANTO CI METTE A RIGETTARE</u>.
E, per di pi√π, a noi interessa solo accettare le parole del linguaggio.

##### Efficienza spaziale - NSPACE
Le classi che misurano "efficienza spaziale" nel caso non deterministico si chiamano <font color="#ff0000">NSPACE</font>: data una <font color="#245bdb">funzione totale e calcolabile f</font> ![[Pasted image 20250424183033.png]]


---

## Classi di complemento
![[Pasted image 20250424183058.png]]


---

### Un paio di questioni
1) Qui stiamo considerando linguaggi sull'alfabeto ${0,1}$ per comodit√† ma possiamo considerare anche altri alfabeti (e lo faremo)
2) La funzione f che definisce una classe di complessit√† (ad esempio `DTIME[`<font color="#245bdb">fn</font>`]`) diamo il nome di <font color="#245bdb">funzione limite</font>
	- che ovviamente deve essere totale e calcolabile senn√≤, per definizione, avremo una funzione che ci dice quante istruzioni esegue una computazione MA di cui non sappiamo il reale valore (inutile se ci pensi!)


---

## Relazioni fra classi di complessit√†
>[!lemma] Teorema 6.8
>![[Pasted image 20250424183845.png]]

La dimostrazione √® facile.
Una macchina deterministica √® **una particolare macchina non deterministica con il grado di non determinismo pari a `1`** e, inoltre
- una parola decisa in un certo numero di passi √® anche accettata in quel certo numero di passi
- una parola decisa utilizzando un certo numero di celle √® anche accettata in quel certo numero di celle


>[!lemma] Teorema 6.9
>![[Pasted image 20250424185029.png]]

Questa dimostrazione segue direttamente dal [[21. Misure di complessit√†#^a43723|Teorema 6.1]]
Sia $L \subseteq \{0,1\}^{*}$ tale che $L \in DTIME[f(n)]$.
Sappiamo, per il Teorema 6.1, che $$\text{spazio} \le \text{tempo}$$ per ogni macchina di Turing:
	se una macchina fa al massimo `t` passi, non pu√≤ usare pi√π di `t` caselle

Perci√≤ $$\text{dspace(T,x)} \le \text{dtime(T,x)}$$e dato che $$\text{dtime} \in O(f(|x|))$$ (per [[22. Classi di complessit√†#^460bf9|definizione di DTIME]]) 
Allora possiamo scrivere $$\text{dspace(T,x)} \le \text{dtime(T,x)}  \in O(f(|x|))$$e quindi anche $$\text{dspace(T,x)} \in O(f(|x|))$$
## ‚úÖ **Conclusione**

> Se $L \in \text{DTIME}[f(n)]$, allora $L \in \text{DSPACE}[f(n)]$

Cio√®: $$\text{DTIME}[f(n)] \subseteq \text{DSPACE}[f(n)]$$
‚úÖ **Vale anche nel caso non deterministico**: $$\text{NTIME}[f(n)] \subseteq \text{NSPACE}[f(n)]$$


>[!lemma] Teorema 6.10
>![[Pasted image 20250424192810.png]]

Per la dimostrazione non ho capito un cazzo, la copio e incollo.
##### üìò Teorema 6.10 (detto in parole semplici)

> Se usi **al massimo `f(n)` celle di memoria** per decidere un problema, allora esiste un modo per risolverlo che richiede **tempo al massimo `2^O(f(n))`** (cio√® tempo esponenziale rispetto allo spazio).

###### Formalmente:
```
DSPACE[f(n)] ‚äÜ DTIME[2^O(f(n))]
NSPACE[f(n)] ‚äÜ NTIME[2^O(f(n))]
```

##### üß† Ok, ma perch√©?
Immagina che la macchina di Turing T usi al massimo `f(n)` celle del nastro per un input lungo `n`.

> üîç Ogni "configurazione" della macchina √®:  
> stato + contenuto del nastro + posizione della testina

Quante possibili **configurazioni diverse** pu√≤ assumere T?

##### Le combinazioni sono tante, ma **finite**! E in particolare:
- Gli **stati** sono un numero fisso, diciamo `|Q|`
- Le celle usate sono al massimo `f(n)`
- Ogni cella pu√≤ contenere uno dei simboli dell‚Äôalfabeto `|Œ£|` (pi√π il blank)
- La testina pu√≤ stare in una delle `f(n)` celle

Allora il numero totale di configurazioni √® al massimo:

```
|Q| √ó |Œ£ + 1|^f(n) √ó f(n)
```

üìå **Questo √® un numero esponenziale rispetto a `f(n)`**  
‚áí diciamo che √® **al massimo `2^O(f(n))` configurazioni**

##### üîÅ E come ci serve questo?
Se conosci **tutte le configurazioni possibili**, puoi:
- simulare la macchina T "dall‚Äôesterno"
- esplorare tutte le possibili sequenze di configurazioni (tipo albero di esecuzione)
- controllare se si arriva a uno stato di accettazione

Questo √® un algoritmo che **decide il linguaggio**, anche se **√® pi√π lento**, perch√© deve controllare tutte le configurazioni.

Ma √® comunque **un algoritmo deterministico** che termina!

##### ‚úÖ Conclusione:

> Se un problema si pu√≤ decidere usando al massimo `f(n)` celle di memoria,
> allora **esiste un algoritmo deterministico** che risolve lo stesso problema in **tempo `2^O(f(n))`**

E lo stesso vale anche nel caso **non deterministico**.

