## Definizione
TCP viene detto orientato alla connessione (connection-oriented) in quanto, prima di effettuare scambi di dati, i processi devono effettuare l'handshake, ossia inviarsi reciprocamente alcuni segmenti preliminari per stabilire i parametri del successivo trasferimento (generalmente vengono inizializzate molte variabili di stato associate alla connessione).

Una connessione TCP offre un servizio full-duplex, ossia i dati tra un mittente ad un altro possono fluire in direzioni opposte nello stesso momento.

Inoltre, una connessione TCP è detta anche punto-a-punto, ossia avviene tra un singolo mittente e un singolo destinatario (non è possibile "multicast", ossia UN mittente -> PIÙ destinatari).

>[!tip] INFO IMPORTANTE
>Sopra il TCP c'è un software che lavora per lui (es. spezzetta i pacchetti, invia cose, ecc.).
>Quindi, quando nominerò TCP, intendo TUTTO, non solo il protocollo.

### Instaurare una connessione
Un processo applicativo client vuole instaurare una connessione con un processo applicativo server.
Innanzitutto il processo applicativo client informa il livello di trasporto client che vuole stabilire una connessione verso il processo server.

Il TCP in esecuzione sul client procede a stabilire una connessione con il TCP del server, in questo modo
- il client invia un primo segmento speciale TCP (tipo gli dice "compare voglio comunicare con te")
- il server risponde con un secondo segmento speciale TCP (gli dice "daje")
- il client invia un terzo segmento TCP che GENERALMENTE già contiene informazioni utili.
Questa procedura viene definita **handshake a tre vie**.

#### Inviare dei dati
![[Pasted image 20250407182229.png]]
Il processo client manda un flusso di dati attraverso una socket e quando hanno raggiunto l'uscita vengono prelevati dal TCP in esecuzione sul client e inseriti nel buffer d'invio TCP (che era stato inizializzato durante l'**handshake a tre vie**).

Bisogna tenere in considerazione che la massima quantità di dati prelevabili e posizionabili in un segmento viene limitata dalla dimensione massima di segmento (MSS, Maximum Segment Size). 

Per decidere questo valore viene scelta la grandezza del frame più grande che può essere inviato al livello di collegamento del mittente, la unità trasmissiva massima (MTU, Maximum Transmission Unit) e viene poi scelto il MSS che riesca a stare all'interno di un singolo frame di collegamento (contando che ci sono anche le intestazioni TCP/IP).

>[!tip] Dimensione MTU e MSS nei protocolli più famosi
>In Ethernet e PPP abbiamo
>- MTU = 1500 byte
>- Intestazione = 40 byte
>
>QUINDI
>- MSS = 1460 byte 

TCP accoppia ogni blocco dati ad un intestazione TCP, andando a creare **segmenti TCP**.
Questi segmenti vengono poi inviati a livello di rete, dove sono incapsulati separatamente nei datagrammi IP.

##### Ricezione del server
Quando all’altro capo TCP riceve un segmento, i dati del segmento vengono memorizzati nel buffer di ricezione della connessione TCP.


## Struttura dei segmenti TCP
![[Pasted image 20250407194343.png|center]]
Il segmento TCP consiste di 
- **campi di Intestazione**
- **campo contenente un blocco di dati** proveniente dall'intestazione

###### Intestazione
Come in UDP, l'intestazione include 
- **numeri di porta di origine e destinazione**
- **checksum**

Oltre a diversi campi quali
- **Numero di sequenza** e **Numero di acknowledgment** (32 bit) utili per implementare il trasferimento dati affidabile
- **Finestra di ricezione** (16 bit), utilizzato per il controllo del flusso
- **Lunghezza dell'intestazione** (4 bit), specifica la lunghezza dell'intestazione TCP in multipli di 32 bit
- **Opzioni**, facoltativo e di lunghezza variabile, viene utilizzato quando client e server negoziano la dimensione massima del segmento (MSS)
- **Flag** (6 bit), dove abbiamo (li ho scritti per completezza ma boh)
	- flag **ACK**, per indicare che il segmento contiene un acknowledgment per un segmento ricevuto con successo
	- bit **RST, SYN, FIN** vengono utilizzati per impostare e chiudere la connessione
	- bit **CWR** e **ECE**, usati nel controllo di congestione esplicito
	- bit **PSH**, che se impostato a 1 indica che il destinatario deve inviare immediatamente i dati al livello superiore
	- bit **URG**, per marcare i dati che il mittente definisce "urgenti"
	
	La posizione dell’ultimo byte di dati urgenti viene denotata dal campo **Puntatore ai dati
	urgenti** (*urgent data pointer field*), di 16 bit. Quando ci sono dati urgenti, TCP deve informare l’entità destinataria al livello superiore e passarle un puntatore alla fine dei dati urgenti.


## Numeri di sequenza e numeri di acknowledgment
Questi due numeri (campi) sono presenti nell'intestazione del segmento TCP.

#### Numero di sequenza
TCP vede i dati come un flusso di byte non strutturati, ma ordinati. 
Il **numero di sequenza per un segmento** è pertanto il primo numero nel flusso di byte del segmento.
	Un esempio semplice
	Immagina di inviare questa frase:  
	👉 _"CIAO COME STAI?"_
		TCP la divide in 3 segmenti:
		1. "CIAO" → numero di sequenza: 0 (perché ci sono i byte da 0 a 3)
		2. " COME" → numero di sequenza: 4
		3. " STAI?" → numero di sequenza: 9

Ogni numero di sequenza viene inserito nel campo numero di sequenza dell’intestazione del segmento TCP appropriato.

#### Numero di acknowledgment
Ricordiamo che TCP è full-duplex, di conseguenza l’Host A può contemporaneamente inviare e ricevere dati dall’Host B (come parte della stessa connessione TCP). I segmenti che provengono dall’Host B presentano un numero di sequenza relativo ai dati che fluiscono da B ad A. 
*Il numero di acknowledgment che l’Host A scrive nei propri segmenti è il numero di sequenza del byte successivo che l’Host A attende dall’Host B*.
![[Pasted image 20250407194408.png]]
##### Esempio per capire meglio
Il pacchetto B invia ad A i byte da `0 a 535`.
A li riceve e invia un ACK a B con scritto `536`, ossia "l'ultimo byte arrivato è il `535`, ora sto aspettando il `536`".

>[!question] E se ACK è `536` ma $A$ riceve `900-1000`?
>Innanzitutti si dice che tale protocollo offre acknowledgment cumulativi.
>Se si verifica questo caso si hanno due scelte
>1) vengono eliminati i byte da `900` a `1000` in attesa degli altri (soluzione semplice ma inefficente)
>2) il destinatario mantiene i byte non ordinati e attende quelli mancanti per colmare i vuoti
>
>NB: L'ACK continua ad essere comunque `536` finché non lo riceve 


### Timeout e stima del tempo di andata e ritorno (RTT)
Anche TCP, come `rdt` implementa un meccanismo di **timeout** e ritrasmissione per recuperare i segmenti persi.
Qui però l'implementazione è un filino più complicata.
La questione più ovvia è la durata degli intervalli di timeout, che chiaramente dovrebbe essere più grande del tempo di andata e ritorno sulla connessione (RTT, Round-Trip Time), ossia del tempo trascorso dall'invio del pacchetto alla recezione dell'acknowledgment.

>[!question] Ma come stimare il tempo dell'RTT?

Si definisce il `Sample-RTT` come la quantità di tempo che intercorre tra l’istante di invio del segmento (ossia quando viene passato a IP) e quello di ricezione dell’acknowledgment del segmento. 

TCP non misura `Sample-RTT` per ogni segmento inviato ma solo per uno alla volta, cioè anche se ci sono più segmenti ancora non confermati TCP NE SCEGLIE SOLO UNO per calcolare il tempo che passa tra l’invio e il relativo acknowledgment. 
Questo è utile perché poi andrà a fare una media tra vari RTT calcolati per poi poter stimare un RTT effettivo finale.
###### ESEMPIO PER FARTI CAPIRE MEGLIO
![[Pasted image 20250407213246.png]]![[Pasted image 20250407213259.png]]Quindi in pratica
- su 3 segmenti ne ha scelto uno solo per calcolare RTT ("meglio una stima esatta che tre approssimate").
	- si salva quell'RTT
- poi magari invia altre tre pacchetti, ne sceglie uno e salva l'RTT 
- alla fine farà una media tra tutti gli RTT

TCP per calcolare questa misura ignora i casi di ritrasmissione perché non sa se l'ACK è riferito alla prima trasmissione o alla seconda. 

Dato che tutti questi valori effettueranno una stima viene definito ***Estimated-RTT*** sulla base di tutti i Sample ottenuti. Ogni volta E-RTT verrà aggiornato secondo:
![[GetImage (36).png]]
Dove: 
- **EstimatedRTT**: è la stima attuale del tempo di andata e ritorno.
- **SampleRTT**: è una nuova misurazione (cioè un RTT misurato da un segmento). 
- `α (alfa)`: è un numero tra 0 e 1, che dice **quanto peso dare alla nuova misura** rispetto alla media passata. (tipicamente `α = 0.125`)
![[GetImage (37).png]]

In questo modo si va ad "aggiustare" pian piano questo valore. 

È possibile anche ottenere di quanto si discosta Sample RTT si discosta da RTT come:
![[GetImage (38).png]]
Dove: 
- **DevRTT**: misura quanto fluttua l’RTT nel tempo (deviazione assoluta). 
- `β (beta)`: peso dato alla nuova variazione. Di solito è 0.25. 
- $|SampleRTT - EstimatedRTT|$: differenza assoluta tra la nuova misura e la stima attuale, cioè quanto è distante il nuovo valore dalla media.
![[GetImage (39).png]]
Il grafico ottenuto sarà questo e si aggiornerà in continuazione:
![[Pasted image 20250407213454.png|center]]

### Mittente TCP (semplificato come le slide) 
Il **mittente TCP** è responsabile di:
- inviare i segmenti verso il destinatario,
- **aspettare conferme (ACK)**,
- **gestire un timer** per ritrasmettere se serve,
- e adattarsi se la rete è lenta o satura.

##### 🔁 FASE 1 – Invio di dati
L’applicazione (tipo un browser o un'app) passa dei dati al livello TCP.
###### ⚙️ Comportamento del mittente:
- TCP crea un **segmento** e gli assegna un **numero di sequenza** (es. 1001)
- Invia il segmento al destinatario
- Se non c’è **già un timer attivo**, ne **avvia uno adesso**

🧠 **Importante:** il timer è sempre legato al **segmento più vecchio non ancora confermato** (quello con il numero di sequenza più basso).

##### ⏱️ FASE 2 – Timer in azione
Serve a evitare di aspettare all'infinito un ACK che potrebbe non arrivare.
###### ⚙️ Funzionamento:
- Se il timer **scade** (cioè l’ACK non arriva in tempo), TCP **ritrasmette** proprio **quel segmento** (il più vecchio non confermato)
- Poi **riattiva il timer**
- Inoltre, **raddoppia il tempo di timeout** per evitare di intasare la rete se c'è congestione → si chiama **backoff esponenziale**

💡 Se il problema si risolve e finalmente arrivano gli ACK, **il timeout torna al valore normale**

##### 📨 FASE 3 – Arrivo di un ACK
Il destinatario riceve il pacchetto e manda un ACK con il numero del **prossimo byte atteso**.
###### ⚙️ Comportamento del mittente:
- Se riceve l’ACK atteso → aggiorna la **SendBase** (cioè il primo byte in attesa di conferma)
- Se ora **non ci sono più segmenti in sospeso**, **ferma il timer**
- Se invece ci sono ancora segmenti in volo **non confermati**, **riattiva il timer** per quello più vecchio rimasto


### Ricevente TCP
Quattro caso
1. **Ordinato** 
	- Il segmento ha il numero di sequenza atteso e tutti i dati precedenti sono già stati ricevuti correttamente 
	- Il ricevente aspetta fino a 500 ms per vedere se arriva subito anche il prossimo segmento, potrebbe mandare un solo ack per entrambi (ack cumulativo) e risparmiare dati. 
	    - Se non arriva niente lui ha comunque ricevuto il suo segmento, invia comunque un ACK. 
	        -  Si chiama ACK ritardato cioè "aspetto un po' magari arriva un altro segmento", se non arriva pazienza. 
    

2. **Segmento ordinato, ma ce n’è già un altro in attesa di ACK** 
	- Segmenti ricevuti in ordine, ma TCP non ha ancora mandato l’ACK del precedente 
	    - Manda ACK cumulativo e li conferma entrambi (un messaggio in meno di ACK) 
    

3. **Segmento fuori ordine** 
	- Il segmento ha un numero di sequenza più avanti di quello atteso, manca un pacchetto 
	    - Invia un ACK duplicato col numero del byte che manca ancora 
    

4. **Arriva un segmento che riempie il buco** 
    - ACK cumulativo di prima


### Diversi scenari 
1. ***Scenario con ACK perso*** 
	Host A invia `Seq=92`, 8 byte. 
	
	Host B riceve e risponde con `ACK=100`, **ma si perde**. 
	
	Host A non riceve l’ACK, **scatta il timeout**. 
	- Ritrasmette `Seq=92`, 8 byte. 
	
	Host B riceve di nuovo quei dati, **ma li aveva già ricevuti**. 
	- Host B reinvia `ACK=100`. 

 **Conclusione**: TCP è **robusto** anche se si perde un ACK → ritrasmette il segmento e tutto continua.
 ![[GetImage (40).png|center]]
 
2. ***Timeout prematuro*** 
	Host A invia: 
	  - `Seq=92`, 8 byte 
	  - `Seq=100`, 20 byte 
	Ma il **timeout scatta troppo presto**, prima che arrivi `ACK=100` 
	- A ritrasmette `Seq=92` di nuovo 
	
	B ha già ricevuto tutto e manda `ACK=120` (**ACK cumulativo**)

**Conclusione**: anche se l’ACK iniziale non è arrivato, **quello cumulativo** (`ACK=120`) lo "copre" e fa andare avanti tutto.
![[GetImage (41).png|center]]


3. ***Ritrasmissione rapida (Fast Retransmit)*** 
	Host A invia 3 segmenti: 
	- `Seq=92` (8 byte), **arriva** 
	- `Seq=100` (20 byte), **si perde** 
	- `Seq=120` (altri dati), **arriva** 
    
	Host B: 
	- Riceve **92** → manda `ACK=100` (si aspetta il byte 100) 
	- Poi riceve **120**, ma manca il pezzo da 100 a 119 
	- **Non può andare avanti** → manda di nuovo `ACK=100` 
	- **E lo fa ancora, ogni volta che riceve dati dopo il buco** 
    
	Quindi Host A riceve:
	- ACK=100 
	- ACK=100 
	- ACK=100 
		→ 3 ACK duplicati! 

**Conclusione**: con 3 ACK duplicati, **TCP attiva la ritrasmissione veloce, senza aspettare il timer**.
![[GetImage (42).png]]


### Controllo di flusso
Quando un destinatario riceve dei dati, TCP li inserisce in un'area chiamata **buffer di ricezione**.

Potrebbe però verificarsi un problema: l'applicazione (browser, programma, ecc...) che legge i dati potrebbe non farlo subito (magari è occupata).
Se il mittente continua ad inviare dati velocemente e il buffer non viene svuotato in tempo, quest'ultimo va in overflow e vengono persi i segmenti in arrivo (scartati).

TCP offre un servizio di **controllo di flusso** alle prorpie applicazioni per evitare che il mittente saturi il buffer del ricevente, il tutto viene fatto paragonando
- velocità di invio del mittente
- velocità di lettura dell'applicazione ricevente

==Come semplificazione si suppone che i segmenti fuori ordine vengano scartati dal destinatario TCP.==

TCP usa una variabile chiamata **finestra di ricezione** che fornisce al mittente una panoramica dello spazio disponibile nel buffer del destinatario.

#### ESEMPIO
- Host A: invia un file di grandi dimensioni - spezzettato in segmenti - all'host B su una connessione TCP 
	- HOST A ha inviato byte `da 0 a 999`
	
- Host B: alloca un buffer di ricezione per la connessione, la dimensione si chiama ***RcvBuffer*** 
    - Ogni tanto il processo applicativo dell'host B legge dal buffer
    - FINO AD ORA, HOST B ha letto byte `699`
###### LATO HOST B
L'host B tiene in considerazione due variabili
- `LastByteRcvd`
	È il numero **dell’ultimo byte arrivato dalla rete** ed entrato nel buffer. 
	- nel nostro esempio è `999`

- `LastByteRead`
	È il numero **dell’ultimo byte che l’applicazione ha letto dal buffer**.
	- nel nostro esempio è `699`

==CI SONO ANCORA **300** BYTE DA DOVER LEGGERE NEL BUFFER==

Dato che TCP non può mandare in overflow il buffer allocato 
	`LastByteRcvd – LastByteRead ≤ RcvBuffer`
	
Definiamo la finestra di ricezione ***rwnd*** e la impostiamo alla quantità di spazio disponibile nel buffer:
	`Rwnd = RcvBuffer – [LastByteRcvd – LastByteRead]`

***Rwnd*** è dinamica e varia col tempo, nella figura sotto
![[GetImage (43).png]]
L'host B quindi comunica all'host A quanto spazio disponibile è presente nel buffer.

###### LATO HOST A
Anche l'host A deve utilizzare due variabili
- `LastByteSent`: ultimo byte **inviato**.
- `LastByteAcked`: ultimo byte per cui ha ricevuto un **ACK**.

La differenza `LastByteSent – LastByteAcked` indica **quanti byte non hanno ancora ancora ottenuto una conferma**.

TCP fa sempre rispettare questa regola
```nginx
LastByteSent – LastByteAcked ≤ rwnd
```
così evita che A riempia il buffer.

>[!danger] PROBLEMA, quando `rwnd = 0` l'host B lo comunica ad A MA POI NON MANDA PIÙ NULLA
>Quindi se si arriva a questa situazione, A rimane bloccato e non saprà più quando il buffer si sarà svuotato

Per risolvere questo problema TCP richiede che A invii comunque ogni tanto dei segmenti "sonda" (di 1 byte) anche se `rwnd = 0`
- quando B risponde, aggiorna il valore di A 
- così A saprà quando può riprendere ad inviare

>[!tip] Menzione carina: UDP NON HA IL CONTROLLO DI FLUSSO
>Se l'applicazione su B è lenta a leggere i dati, il buffer si riempie → **si perdono i segmenti** (non vengono messi in coda, vengono **scartati**).


## Spiegazione esaustiva sulla gestione della connessione TCP
Come detto prima, il protocollo TCP prevedere la **three-way handshake** per stabilire una connessione.
Vediamo ora più nel dettaglio come avviene
###### PASSO 1 - Il client invia un SYN
Il client vuole avviare una connessione.
- Invia un **segmento SYN** (con il bit `SYN = 1`) che NON CONTIENE DATI APPLICATIVI ma
	- include il numero di sequenza iniziale scelto casualmente -> `client_isn` (questo serve per numerare i byte che verranno inviati successivamente)
- Il pacchetto viene incapsulato in un datagramma IP e inviato

###### PASSO 2 - Il Server risponde con un SYN-ACK
Il server riceve il segmento SYN.
- Alloca buffer e variabili TCP per la nuova connessione
- Invia un SYNACK (con **`SYN = 1`** e `ACK = 1`), che
	- conferma la ricezione del `client_isn` -> `ACK = client_isn + 1`
	- include il suo numero di sequenza -> `server_isn`

###### PASSO 3 - Il client risponde con un ACK (e se vuole anche dei dati)
Il client riceve il SYNACK.
- Alloca anche lui buffer e variabili TCP.
- Risponde con un **segmento ACK**:
    - `ACK = server_isn + 1`, per confermare la ricezione.
    - `SYN = 0`, perché la connessione è ora **stabilita**.
    - Può già contenere **dati** dell'applicazione (es. richiesta HTTP).

Ora la connessione è stabilita e sicura , gli host possono scambiarsi dati normalmente

![[Pasted image 20250408114506.png|center]]

>[!tip] Questa procedura è molto utile perché evita problemi e attacchi
>Ad esempio, evita una connessione "fantasma" con un host che non ha mai risposto

#### Chiusura di una connessione TCP
Anche la chiusura avviene in più passaggi.

**Esempio: il client vuole chiudere**
1. Il **client** manda un segmento con **FIN = 1** → segnala “voglio chiudere”.
2. Il **server** risponde con un **ACK** → “ok, ho ricevuto la tua richiesta”.
3. Poi anche il **server** manda il suo **FIN = 1** → “ora chiudo anch’io”.
4. Infine, il **client risponde con un ACK** → “chiusura completata”.
![[Pasted image 20250408114531.png|center]]

## I vari stati TCP (TCP states)
Durante una connessione TCP, il protocollo passa attraverso diversi stati utili per coordinare l'apertura, l'uso e la chiusura della connessione in modo affidabile.
##### IL CLIENT VUOLE CHIUDERE LA CONNESSIONE
###### LATO CLIENT
***APERTURA DELLA CONNESSIONE***
1. **CLOSED**  
    ➝ Stato iniziale (nessuna connessione attiva).
    
2. **SYN_SENT**  
    ➝ Il client ha inviato il segmento SYN e **aspetta** la risposta dal server (SYN-ACK).
    
3. **ESTABLISHED**  
    ➝ Il client ha ricevuto il SYN-ACK e risposto con un ACK.  
    ✅ Connessione attiva → si possono scambiare **dati applicativi**.

***CHIUSURA DELLA CONNESSIONE***
1. **FIN_WAIT_1**  
    ➝ Il client ha inviato un segmento con **FIN = 1** (vuole chiudere)  
    e **attende un ACK** dal server.
    
2. **FIN_WAIT_2**  
    ➝ Il client ha ricevuto l’ACK del FIN.  
    Ora aspetta che **anche il server mandi il suo FIN**.
    
3. **TIME_WAIT**  
    ➝ Il client ha ricevuto il FIN del server e **ha inviato un ACK finale**.  
    Resta in questo stato **per sicurezza**, nel caso l’ultimo ACK **vada perso**.
    
    🔁 Durante **TIME_WAIT**, se il server non riceve l’ACK, può rimandare il FIN e il client sarà pronto a rispondere di nuovo.
    
    La durata di TIME_WAIT dipende dall'implementazione del SO, ma dopo di ché 
    - la connessione è definitivamente chiusa
    - le risorse vengono liberate (porte, buffer, variabili TCP)

![[Pasted image 20250408114945.png|center]]

###### LATO SERVER
Quando è il client a chiudere la connessione, il server
- In genere passa da **ESTABLISHED** a **CLOSE_WAIT**, poi a **LAST_ACK**, e infine **CLOSED**.
- Le **transizioni sono simili** a quelle del client ma in ordine "speculare", perché il server **risponde** alla richiesta di chiusura.

![[Pasted image 20250408121541.png|center]]

>[!question] Cosa succede se il pacchetto arriva a una porta sbagliata?
>Nel senso, cosa accadrebbe se un host ricevesse un **segmento TCP SYN**, ma **non ci fosse nessun servizio in ascolto** sulla porta di destinazione? (es. porta 80, ma non c’è un web server attivo).

La soluzione dipende da quale protocollo si utilizza
###### TCP
L'host risponde con un segmento **RST** (reset), con bit `RST = 1`
###### UDP
UDP è più semplice, ma se riceve un pacchetto destinato a **una porta senza socket attiva**, l’host risponde con un messaggio **ICMP "Port Unreachable"**.

### Nmap
La domanda da porci è
>[!question] Come capire quali porte sono aperte su un Host?

Viene utilizzato Nmap, uno strumento usato per fare **scansioni di rete**, molto utile per capire:
- quali **porte TCP o UDP** sono aperte su un computer (cioè su quali porte ci sono programmi attivi),
- se c'è un **firewall** che blocca certi pacchetti,
- quale **sistema operativo o versione di software** sta usando l’host.

Per fare questo, **simula delle connessioni** TCP, e osserva **le risposte** che riceve.

Supponiamo che tu voglia scoprire se un servizio (es. un'applicazione web) è attivo su una porta, ad esempio la **porta TCP 6789**.
Nmap manda a quella porta un pacchetto **SYN**, proprio come farebbe un client TCP per avviare una connessione.
Poi guarda **la risposta dell’host** per capire cosa c'è su quella porta.
###### TRE CASI POSSIBILI
1. **L’host risponde con un pacchetto SYN-ACK**
	-> la porta è aperta e quindi c'è un servizio attivo

2. **L’host risponde con un pacchetto RST**
	-> la porta è chiusa MA non c'è alcun firewall che blocca i pacchetti

3. **L’host non risponde affatto**
	-> la porta è filtrata, poiché c'è un firewall che blocca i pacchetti (non sa comunque se la porta è aperta o chiusa)