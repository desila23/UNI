## MUTEX
Un "mutex" √® una struttura dati specifica per la Mutua Esclusione.

Pu√≤ avere due stati:
- **locked** (bloccato)
- **unlocked** (sbloccato)

Viene rappresentato o con un bit o con un intero (`0`  = unlocked, `1` = locked)

Abbiamo due procedure principali:
- `mutex_lock`, blocca il mutex
- `mutex_unlock`, sblocca il mutex


#### Funzionamento del mutex
- Quando un thread vuole accedere a una **regione critica**, tenta di bloccare l'accesso tramite `mutex_lock`.
	- se il mutex √® unlocked, il thread entra
	- se il mutex √® locked, il thread attende

- Quando il thread ha finito, chiama `mutex_unlock` e per liberare la risorsa

>[!important] NON SI UTILIZZA IL "BUSY WAITING"
>Se un thread non pu√≤ acquistare un lock, chiama `thread_yield` per cedere la CPU ad un altro thread.


##### Considerazioni aggiuntive
- I mutex possono essere implementati nello spazio utente con istruzioni come `TSL` o `XCHG`
	
- Alcuni pacchetti di thread offrono `mutex_trylock`, con cui si tenta di acquisire il lock o restituisce un errore, senza bloccare il processo corrente
	
- i mutex sono efficaci quando i thread operano in uno spazio di indirizzi comune
	
- la condivisione di memoria tra i processi pu√≤ essere gestita tramite kernel o con l'aiuto di sistemi operativi che permettono la condivisione di parti dello spazio degli indirizzi.


## PHTREAD
√à una libreria che fornisce funzione per sincronizzare i thread.

| <center><font color="#d83931">Thread Call</font></center> | <font color="#d83931"><center>Description</center></font>                                                                                                          |
| --------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| <center>**`pthread_mutex_init`**</center>                 | Inizializza un oggetto mutex per l‚Äôuso, configurando le risorse necessarie.                                                                                        |
| <center>**`pthread_mutex_destroy`**</center>              | Distrugge un oggetto mutex, liberando le risorse associate.<br>Deve essere chiamato solo se il mutex non √® detenuto da alcun thread.                               |
| <center>**`pthread_mutex_lock`**</center>                 | Blocca un mutex, sospendendo l‚Äôesecuzione del thread chiamante se il mutex √® gi√† occupato da un altro thread.                                                      |
| <center>**`pthread_mutex_trylock`**</center>              | Tenta di bloccare un mutex senza sospendere l‚Äôesecuzione.<br>Se il mutex √® gi√† bloccato, la funzione restituisce immediatamente con un codice di errore specifico. |
| <center>**`pthread_mutex_unlock`**</center>               | Sblocca un mutex, permettendo ad altri thread di acquisirlo.<br>Deve essere chiamato solo dal thread che detiene il lock.                                          |

>[!question]- Quando usare `lock` e quando `trylock`?
>- `pthread_mutex_lock` lo uso quando il thread deve assolutamente accedere alla risorsa e non pu√≤ fare altro finch√© non ottiene il lock, Nel caso pu√≤ aspettare
>- `pthread_mutex_trylock` lo uso se
>	- il thread deve accedere alla risorsa ma nel caso pu√≤ fare altro
>	- voglio verificare se il lock √® libero o meno senza interrompere nulla
>	```c
>	if (pthread_mutex_trylock(&mutex) == 0) {
> 	  // Se otteniamo il lock, eseguiamo le operazioni protette
> 	   printf("Ho ottenuto il lock e sto eseguendo operazioni.\n");
> 	   sleep(2); // Simuliamo qualche operazione lunga
> 	   printf("Ho terminato e rilascio il lock.\n");
> 	   // Rilasciamo il lock
> 	   pthread_mutex_unlock(&mutex);
>	} else {
> 	   // Se il lock non √® disponibile, continuiamo con altre operazioni
> 	   printf("Non sono riuscito a ottenere il lock, continuo con altre operazioni.\n");
>	}
>	```


## Semafori o mutex
- **FINALIT√Ä**:
	- Il **Mutex** √® utilizzato per garantire l'esclusione mutua e protegge una risorsa condivisa (NON √à UTILE PER LA SINCRONIZZAZIONE)
	- Il **Semaforo** pu√≤ essere utilizzato per controllare l'accesso ad una risorsa condivisa MA pu√≤ essere usato per la sincronizzazione tra thread

- **SEMANTICA**:
	- Il **Mutex** ha una semantica di "propriet√†", il che significa che solo il thread che lo ha acquisito pu√≤ rilasciarlo
	- Il **Semaforo** non ha una semantica di propriet√†, qualsiasi thread pu√≤ aumentare o diminuire il conteggio del semaforo


## Variabili condizionali 
Come detto prima, il mutex da solo non pu√≤ sincronizzare l'attesa su condizioni specifiche.
Per farlo utilizziamo le **variabili condizionali** (`phtread_cond`).

Immagina che un thread prenda il mutex ma deve aspettare passivamente che un contatore arrivi fino a 10
- **SENZA VARIABILI CONDIZIONALI**, lui blocca il mutex ma magari altri eventuali thread potrebbero utilizzarlo senza problemi.
- **CON VARIABILI CONDIZIONALE**, io posso far s√¨ che il `thread 1` si metta in attesa, do il mutex ad un altro thread e poi quando il contatore arriva a 10 rid√≤ il mutex al `thread 1`

###### VEDENDOLO IN OTTICA PRODUTTORE-CONSUMATORE
Un thread pu√≤ attendere con `pthread_cond_wait` su una variabile condizionale finch√© una condizione specifica non √® soddisfatta
- Durante l'attesa, il thread rilascia temporaneamente il mutex, permettendo agli altri thread di accedere alla risorsa 	
- Usando una variabile condizionale, il consumatore pu√≤ sospendersi in attesa finch√© il buffer non √® pieno (o comunque finch√© non c'√® almeno un elemento), senza consumare risorse CPU
	- Quando il produttore aggiunge un elemento al buffer, invia un segnale                                (`pthread_cond_signal`) che risveglia il consumatore.

| <center><font color="#d83931">Thread Call</font></center> | <font color="#d83931"><center>Description</center></font>                                                                                                                                                       |
| --------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <center>**`pthread_cond_init`**</center>                  | Inizializza una variabile di condizione (`pthread_cond_t`) per consentire la sincronizzazione tra thread. La variabile di condizione viene associata a un mutex per coordinare l‚Äôaccesso a risorse condivise.   |
| <center>**`pthread_cond_destroy`**</center>               | Distrugge una variabile di condizione, liberando le risorse associate. Deve essere chiamata solo quando non ci sono thread in attesa sulla condizione.                                                          |
| <center>**`pthread_cond_wait`**</center>                  | Blocca il thread chiamante in attesa della segnalazione di una condizione. Il thread deve detenere un lock sul mutex associato, che viene rilasciato automaticamente durante l‚Äôattesa e riacquisito al termine. |
| <center>**`pthread_cond_signal`**</center>                | Risveglia uno dei thread in attesa sulla variabile di condizione. Se nessun thread √® in attesa, la segnalazione viene persa. Questo √® utile per notificare il cambiamento di stato di una risorsa condivisa.    |
| <center>**`pthread_cond_broadcast`**</center>             | Risveglia tutti i thread in attesa sulla variabile di condizione. Questo √® utile quando un evento deve notificare pi√π thread contemporaneamente, ad esempio, quando una risorsa diventa disponibile per tutti.  |

###### SENZA `pthread_cond_wait` USI IL BUSY-WAITING
```c
pthread_mutex_lock(&mutex);
while (buffer == 0) { // Controllo continuo della condizione (inefficiente)
    pthread_mutex_unlock(&mutex);
    usleep(1000); // Ritardo per ridurre il busy-waiting (non ottimale)
    pthread_mutex_lock(&mutex);
}
consume(buffer);
pthread_mutex_unlock(&mutex);
```
Il consumatore prende il `mutex`; entra nel `while` e se il buffer √® vuoto rilascia il `mutex`, si mette a dormire per un po' e poi lo riprende e NEL CASO ricomincia il ciclo 
Il consumatore controlla continuamente se `buffer == 0`, sprecando risorse CPU.

###### CON `pthread_cond_wait` √à TUTTO PI√ô BELLO
```c
pthread_mutex_lock(&mutex);
while (buffer == 0) {
    // Attesa passiva finch√© il buffer non √® pieno
    pthread_cond_wait(&cond, &mutex)
}
consume(buffer);
pthread_mutex_unlock(&mutex);
```
Il consumatore si sospende senza consumare CPU finch√© il produttore non segnala                          (`pthread_cond_signal`) che il buffer non √® pi√π vuoto.

###### ESEMPIO DEL PROF
```c
for (i = 1; i < = MAX; i++) {
    pthread_mutex_lock(&the_mutex);
	
    while (buffer != 0) {
        pthread_cond_wait(&condp, &the_mutex);
    }
	
    // ... altre operazioni sulla risorsa condivisa ...
}
```
- **Protezione della risorsa condivisa**: `pthread_mutex_lock` assicura che solo un thread alla volta acceda alla risorsa condivisa (in questo caso il buffer)
	
- **Attesa condizionale**: Quando un thread chiama `pthread_cond_wait` avvengono due operazioni atomiche. Il thread:
	- Rilascia il mutex
	- Mette il thread in uno stato di attesa sulla variabile condizionale
	
- Quindi se un produttore detiene il mutex, se viene messo in attesa lo lascia temporaneamente agli altri
	- in questo modo il consumatore (o un altro thread) pu√≤ acquisire il mutex, fare le sue cose e mandare un segnale alla variabile condizionale usando `pthread_cond_signal` e SE PU√í il produttore lo riprende per fare le sue cose


>[!tip] COMODIT√Ä DELLE VARIABILI CONDIZIONALI
>- A differenza dei semafori, le variabili condizionali **non accumulano segnali**
>- Se un `signal` viene inviato ma nessun processo √® in attesa, il segnale viene perso.

---

## I MONITOR
La comunicazione tra processi tramite mutex e semafori non √® semplice.
Per questo Hansen e Hoare proposero il concetto di "**monitor**".

Un **monitor** √® un **meccanismo di sincronizzazione** ad alto livello progettato per facilitare la gestione della **mutua esclusione** e della **sincronizzazione** tra processi o thread.

Possiamo considerarlo come un "contenitore logico" che combina:
  - Dati condivisi che devono essere protetti (**variabili condivise**).
 - Operazioni sicure per manipolare quei dati (**procedure**).
 - Meccanismi di sincronizzazione (**wait** e **signal** con mutua esclusione garantita automaticamente). 

In pratica puoi vederlo come *IL COMPORTAMENTO DEL CODICE CHE SCRIVI*.

>[!tip] Linguaggi come `Java` supportano i monitor


###### PSEUDOCODICE DI MONITOR PER PRODUTTORE-CONSUMATORE
```scss
monitor example
    integer i;
    condition c;
	
    procedure producer();
        ...
    end;
	
    procedure consumer();
        ...
    end;

end monitor;
```

#### Monitor: Produttore-Consumatore
```c
monitor ProdCons {
    condition full, empty;     // condizioni di buffer pieno e vuoto
    int count = 0;             // elementi presenti nel buffer
	
    void enter(int item) {     // PRODUTTORE
        if (count == N) {      // se il buffer √® pieno
	        wait(full);        // si mette in attesa di un signal(full)
        }
        insert_item(item);     // inserisce l'item
        count++;               // incrementa il conteggio degli elementi
        if (count == 1) {      // se l'item inserito √® il primo
	        signal(empty);     // manda un segnale al consumatore
	    }
    }
	
    void remove(int *item) {   // CONSUMATORE
        if (count == 0) {      // se il buffer √® vuoto
	        wait(empty);       // si mette in attesa di un signal(empty)
        }
        *item = remove_item(); // rimuove un item dal buffer
        count--;               // crescrementa il conteggio degli elementi
        if (count == N-1) {    // se ha rimosso un item
	        signal(full);      // manda un segnale al produttore
	    }
    }
}
```
##### COSA SUCCEDE
***PRODUTTORE***
- Il produttore vede se il buffer √® pieno (`count == N`) e se lo √® si mette in attesa (`wait(full)`) che il consumatore invii un `signal(full)`, banalmente possiamo vederli cos√¨
	- `wait(full)`, il produttore dice "*CAZZO DEVO ASPETTARE PERCH√â IL BUFFER √à PIENO*"
	- `signal(full)`, il consumatore dice "*FRA IL BUFFER NON √à PI√ô PIENO*"
	
- Se non √® pieno inserisce un item (`insert_item(item)`) e incrementa il conteggio (`count++`)
	
- Se l'elemento inserito √® il primo (`count == 1`), invia un segnale al consumatore                          (`signal(empty)`), anche qui possiamo vederla tipo
	- `wait(empty)`, il consumatore dice "*DIO, DEVO ASPETTARE PERCH√â IL BUFFER √à VUOTO*"
	- `signal(empty)`, il produttore dice "*COMPARE CHILL, IL BUFFER NON √à PI√ô VUOTO*"

>[!question]- Perch√© mettiamo `if (count == 1)`?
>Perch√© quando il produttore ha inserito il primissimo elemento vuol dire che il buffer non √® pi√π vuoto.
>Sveglio TUTTI i consumatori.
>Possono accadere due cose:
>1. un consumatore √® velocissimo, prende subito elemento; il buffer √® di nuovo vuoto (`count = 0`) e tutti i consumatori tornano a dormire.
>	- DEVO RISVEGLIARLI DI NUOVO, quindi grazie a `count == 1` posso risvegliarli
>2. i consumatori sono lenti e il produttore mette altri elementi sul buffer
>	- NON DEVO SVEGLIARLI perch√© sono tutti gi√† svegli e si stanno dirigendo verso il buffer


***CONSUMATORE***
- Il consumatore vede se il buffer √® vuoto (`count == 0`) e se lo √® si mette in attesa che il produttore invii un `signal(empty)`
	
- Se non √® vuoto rimuove un item (`remove_item`) e decrementa il conteggio (`count - -`) 
	
- Se l'elemento rimosso √® l'ultimo (`count == N-1`), invia un segnale al produttore (`signal(full)`) 

>[!question] Perch√© mettiamo `if (count == N-1)`? Arrivaci da solo 


#### Funzione produttore
```c
void producer() {
    int item;
    while (TRUE) {
        item = produce_item();
        ProdCons.enter(item);
    }
}
```

#### Funzione consumatore
```c
void consumer() {
    int item;
    while (TRUE) {
        ProdCons.remove(&item);
        consume_item(item);
    }
}
```


>[!example]- Differenze tra `sleep/wakeup` e `wait/signal`
>`sleep/wakeup`
>- meccanismi pi√π primitivi con il problema della race condition (il processo A vuole svegliare B ma B sta gi√† sotto le coperte)
>
>`wait/signal`
>- Sono protetti da **mutua esclusione** all'interno del monitor


>[!tip]- Perch√© sembra che il monitor sia solo il codice?
>
Questa sensazione deriva dal fatto che, nei linguaggi come **C**, non esiste un costrutto "monitor" nativo. Scrivendo codice come sopra, **tu definisci la logica** di un monitor, ma il compilatore **non lo riconosce automaticamente**. Devi implementare tu i meccanismi di mutua esclusione e sincronizzazione usando primitive come semafori o mutex.
>
Invece, in linguaggi come **Java**, i monitor sono **costrutti nativi**.


---

## SCAMBI DI MESSAGGI
Lo scambio di messaggi √® una tecnica di comunicazione tra processi che non utilizza memoria condivisa, e si basa su due primitive:
- `send`, che invia un messaggio ad un altro processo
- `receive`, che riceve un messaggio da un altro processo

√à molto utile nei sistemi distribuiti, dove i processi non condividono memoria e comunicano tramite rete.
#### PROBLEMI
- **Messaggi persi** 
	- I messaggi possono essere persi durante la trasmissione (es. problemi di rete)
	
- **Necessit√† di acknowledgment**
	- Serve un meccanismo per confermare che un messaggio √® stato ricevuto correttamente
	
- **Autenticazione**
	- Bisogna verificare che il mittente del messaggio sia la persona corretta
	
- **Denominazione dei processi**
	- I processi devono sapere a chi inviare e da chi ricevere


### Scambio di messaggi: Produttore-Consumatore
Questa √® una soluzione al classico problema ma senza memoria condivisa e usando solo messaggi.
###### FUNZIONAMENTO
- Si utilizzano `N messaggi`, simili agli `N posti` del buffer nella memoria condivisa
	- Il consumatore invia al produttore `N messaggi` **vuoti** (uno alla volta)
	- Il produttore prende un messaggio vuoto, **lo riempie e lo invia**
	- Il consumatore legge il messaggio, **lo elabora e lo riinvia (vuoto)**

In questo modo il numero totale di messaggi rimane costante e gestito dal SO.
Questa soluzione garantisce efficienza.

###### CODICE
***PRODUTTORE***
```c
void producer() {
    int item;
    message msg;
	
    while (TRUE) {
        item = produce_item();       // produce l'item
        receive(consumer, &msg);     // riceve dal consumatore il messaggio (vuoto)
        build_message(&msg, item);   // costruisce il messaggio inserendo l'item
        send(consumer, &msg);        // invia al consumatore il messaggio (pieno)
    }
}
```

***CONSUMATORE***
```c
#define N 100

void consumer() {
    int item, i;
    message msg;
	
    for (i = 0; i < N; i++) {
        send(producer, &msg);      // invia al produttore un messaggio vuoto (per 
                                   // volta)
    }
	
    while (TRUE) {
        receive(producer, &msg);   // riceve dal produttore il messaggio (pieno)
        item = extract_item();     // estrare l'item dal messaggio
        send(producer, &msg);      // riinvia al produttore il messaggio (vuoto)
        consume_item(item);        // consuma l'item
    }
}

```

>[!warning] N.B.: Viene eseguito prima il `ciclo for` nel consumatore e poi i due cicli `while`
>

#### Problematiche
- Se il produttore √® pi√π veloce, tutti i messaggi saranno pieni e quindi deve aspettare
- Se il consumatore √® pi√π veloce, tutti i messaggi saranno vuoti e quindi deve aspettare

#### Indirizzamento dei messaggi
Quando i messaggi devono essere scambiati tra processi diversi, √® necessario un meccanismo per identificare chi invia a chi riceve.

Due soluzioni possibili
- Ogni processo ha un **indirizzo univoco** che permette di identificare a chi inviare e da chi ricevere
- Invece di inviare direttamente il messaggio al destinatario, questo viene inviato a una **Mailbox** (una sorta di buffer)
	- la mailbox funge da intermediari che conservano il messaggio fino a quando il destinatario √® pronto per riceverlo
	- in questo modo il mittente non si blocca e continua a fare il suo lavoro

#### Applicazioni
- Scambio di messaggi usato in programmazione parallela
- **MPI** (Message Passing Interface) √® un esempio usato in elaborazioni scientifiche


### BARRIERE
Le barriere sono utilizzare per sincronizzare processi o thread (**strettamente dipendenti**) in calcoli paralleli e servono a garantire che i processi avanzino insieme tra diverse fasi di un calcolo o un operazione.

In pratica funziona cos√¨
- Se un processo arriva alla barriera prima degli altri, li **aspetta**
- Quando tutti i processi sono arrivati alla barriera, **avanzano insieme**
![[Pasted image 20241114111924.png]]


---

## INVERSIONE DELLE PRIOTIT√Ä
![[Pasted image 20241114112324.png]]
###### PROBLEMA
- Il **thread di bassa priorit√†** aveva la risorsa condivisa (bloccata dal mutex) ma non la CPU
- Il **thread di alta priorit√†** necessitava della risorsa condivisa ma era bloccata
- Il **thread di media priorit√†** aveva la CPU (perch√© ha pi√π priorit√† del thread con bassa priorit√†)
###### RISULTATO
Il **thread di alta priorit√†** √® rimasto bloccato (anche se di norma ha priorit√† massima) e quindi attivava un riavvio del sistema.

Questo caso viene descritto come **inversione delle priorit√†** (in pratica sono tutte sballate).

###### SOLUZIONE
La NASA ha risolto il problema introducendo il **protocollo di eredit√† delle priorit√†** (*Priority Inheritance*)
- quando un **thread di alta priorit√†** attende una risorsa bloccata da un **thread di bassa priorit√†**, il sistema "eleva" temporaneamente la sua priorit√† al livello del thread bloccante (poteva succedere anche con priorit√† media, ecco perch√© `livello del thread bloccante`);
- in questo modo il **thread di bassa priorit√†** pu√≤ completare rapidamente il lavoro e rilasciare il *mutex*, consentendo al **thread di alta priorit√†** di procedere;
- una volta completato il suo lavoro, il **thread di priorit√† bassa** torna alla sua priorit√† originale.

>[!example]- Una versione semplificata
>IL PC √à UNO SOLO
>- **Andrea** (alta priorit√†) deve giocare a GOW
>- **Luca** (bassa priorit√†) √® nella lobby di fortnite
>- **Samuele** (priorit√† media) sta vedendo un ep. di Blue Lock sul Tablet, ma sta continuamente interrompendo Luca chiedendogli di fargli vedere le skin che ha nel suo armadietto
>
>RISULTATO: 
>- Luca non riesce ad uscire dal gioco
>- Andrea, che avrebbe priorit√† alta, aspetta inutilmente
>
>SOLUZIONE CON ***PROTOCOLLO DI EREDIT√Ä DELLE PRIORIT√Ä***
>- Quando Andrea aspetta Luca, Luca **eredita temporaneamente** la priorit√† di Andrea
>- Luca pu√≤ andare su `quit` per poi uscire, ignorando completamente il povero Samuele che voleva solo vedere le skin üòî
>- Una volta uscito dal gioco, Luca torna alla sua priorit√† normale (godo coglione)



## READ-COPY-UPDATE
##### OBIETTIVO di base
- Permettere **accessi concorrenti senza blocchi** tra lettori e scrittori.
- Ridurre i costi di sincronizzazione (come mutex o semafori) per migliorare le prestazioni in ambienti multithread.
##### Problema
- Senza una gestione attenta, lettori e scrittori possono accedere simultaneamente a strutture di dati, portando a dei casini.

##### PRINCIPIO DI READ-COPY-UPDATE
L'idea base √® **separare i lettori dagli scrittori** attraverso un meccanismo che consente a entrambi di lavorare senza interferenze dirette.
##### Principio di base
1. **Read (lettura):**
    - I lettori possono accedere ai dati **senza lock**.
    - Non c'√® rischio che i lettori leggano dati incoerenti, perch√© vedono solo versioni complete della struttura.
    
2. **Copy (copia):**
    - Quando uno scrittore deve aggiornare i dati, crea una **copia della struttura** da modificare.
    - La copia viene modificata senza interferire con i lettori che stanno usando la versione attuale.
	
3. **Update (aggiorna):**
    - Una volta completata la modifica, lo scrittore **sostituisce la vecchia versione con la nuova**.
    - I nuovi lettori iniziano a usare la nuova versione, mentre quelli gi√† attivi continuano a leggere la vecchia. NON SI AVR√Ä MAI UN MIX.

###### AGGIUNGERE UN NODO
![[Pasted image 20241114115954.png]]

###### TOGLIERE NODI
![[Pasted image 20241114120005.png]]
#### Problema: Quando liberare B e D?
- In un sistema RCU, le vecchie versioni di una struttura (come `B` e `D`) non possono essere liberate immediatamente dopo l'aggiornamento.
	- Questo perch√© potrebbero esserci ancora lettori che stanno accedendo alla vecchia versione.
- Il problema diventa: **Come sapere quando √® sicuro liberare la memoria?**
#### Soluzione RCU: Grace Period
Il **Grace Period** √® un meccanismo utilizzato per determinare quando una vecchia versione di dati pu√≤ essere liberata in sicurezza.
- Si ha un intervallo di tempo durante il quale si aspetta che **tutti i lettori** abbiano completato l'accesso alla vecchia versione dei dati.
- Durante questo periodo, i thread che leggono **non si bloccano** e **non vanno in sleep**, quindi non interrompono l'esecuzione.