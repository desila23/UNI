## MUTEX
Un "mutex" è una struttura dati specifica per la Mutua Esclusione.

Può avere due stati:
- **locked** (bloccato)
- **unlocked** (sbloccato)

Viene rappresentato o con un bit o con un intero (`0`  = unlocked, `1` = locked)

Abbiamo due procedure principali:
- `mutex_lock`, blocca il mutex
- `mutex_unlock`, sblocca il mutex


#### Funzionamento del mutex
- Quando un thread vuole accedere a una **regione critica**, tenta di bloccare l'accesso tramite `mutex_lock`.
	- se il mutex è unlocked, il thread entra
	- se il mutex è locked, il thread attende

- Quando il thread ha finito, chiama `mutex_unlock` e per liberare la risorsa

>[!important] NON SI UTILIZZA IL "BUSY WAITING"
>Se un thread non può acquistare un lock, chiama `thread_yield` per cedere la CPU ad un altro thread.


##### Considerazioni aggiuntive
- I mutex possono essere implementati nello spazio utente con istruzioni come `TSL` o `XCHG`
	
- Alcuni pacchetti di thread offrono `mutex_trylock`, con cui si tenta di acquisire il lock o restituisce un errore, senza bloccare il processo corrente
	
- i mutex sono efficaci quando i thread operano in uno spazio di indirizzi comune
	
- la condivisione di memoria tra i processi può essere gestita tramite kernel o con l'aiuto di sistemi operativi che permettono la condivisione di parti dello spazio degli indirizzi.


## PHTREAD
È una libreria che fornisce funzione per sincronizzare i thread.

| <center><font color="#d83931">Thread Call</font></center> | <font color="#d83931"><center>Description</center></font>                                                                                                          |
| --------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| <center>**`pthread_mutex_init`**</center>                 | Inizializza un oggetto mutex per l’uso, configurando le risorse necessarie.                                                                                        |
| <center>**`pthread_mutex_destroy`**</center>              | Distrugge un oggetto mutex, liberando le risorse associate.<br>Deve essere chiamato solo se il mutex non è detenuto da alcun thread.                               |
| <center>**`pthread_mutex_lock`**</center>                 | Blocca un mutex, sospendendo l’esecuzione del thread chiamante se il mutex è già occupato da un altro thread.                                                      |
| <center>**`pthread_mutex_trylock`**</center>              | Tenta di bloccare un mutex senza sospendere l’esecuzione.<br>Se il mutex è già bloccato, la funzione restituisce immediatamente con un codice di errore specifico. |
| <center>**`pthread_mutex_unlock`**</center>               | Sblocca un mutex, permettendo ad altri thread di acquisirlo.<br>Deve essere chiamato solo dal thread che detiene il lock.                                          |

>[!question]- Quando usare `lock` e quando `trylock`?
>- `pthread_mutex_lock` lo uso quando il thread deve assolutamente accedere alla risorsa e non può fare altro finché non ottiene il lock, Nel caso può aspettare
>- `pthread_mutex_trylock` lo uso se
>	- il thread deve accedere alla risorsa ma nel caso può fare altro
>	- voglio verificare se il lock è libero o meno senza interrompere nulla
>	```c
>	if (pthread_mutex_trylock(&mutex) == 0) {
> 	  // Se otteniamo il lock, eseguiamo le operazioni protette
> 	   printf("Ho ottenuto il lock e sto eseguendo operazioni.\n");
> 	   sleep(2); // Simuliamo qualche operazione lunga
> 	   printf("Ho terminato e rilascio il lock.\n");
> 	   // Rilasciamo il lock
> 	   pthread_mutex_unlock(&mutex);
>	} else {
> 	   // Se il lock non è disponibile, continuiamo con altre operazioni
> 	   printf("Non sono riuscito a ottenere il lock, continuo con altre operazioni.\n");
>	}
>	```


## Semafori o mutex
- **FINALITÀ**:
	- Il **Mutex** è utilizzato per garantire l'esclusione mutua e protegge una risorsa condivisa (NON È UTILE PER LA SINCRONIZZAZIONE)
	- Il **Semaforo** può essere utilizzato per controllare l'accesso ad una risorsa condivisa MA può essere usato per la sincronizzazione tra thread

- **SEMANTICA**:
	- Il **Mutex** ha una semantica di "proprietà", il che significa che solo il thread che lo ha acquisito può rilasciarlo
	- Il **Semaforo** non ha una semantica di proprietà, qualsiasi thread può aumentare o diminuire il conteggio del semaforo


## Variabili condizionali 
Come detto prima, il mutex da solo non può sincronizzare l'attesa su condizioni specifiche.
Per farlo utilizziamo le **variabili condizionali** (`phtread_cond`).

Immagina che un thread prenda il mutex ma deve aspettare passivamente che un contatore arrivi fino a 10
- **SENZA VARIABILI CONDIZIONALI**, lui blocca il mutex ma magari altri eventuali thread potrebbero utilizzarlo senza problemi.
- **CON VARIABILI CONDIZIONALE**, io posso far sì che il `thread 1` si metta in attesa, do il mutex ad un altro thread e poi quando il contatore arriva a 10 ridò il mutex al `thread 1`

###### VEDENDOLO IN OTTICA PRODUTTORE-CONSUMATORE
Un thread può attendere con `pthread_cond_wait` su una variabile condizionale finché una condizione specifica non è soddisfatta
- Durante l'attesa, il thread rilascia temporaneamente il mutex, permettendo agli altri thread di accedere alla risorsa 	
- Usando una variabile condizionale, il consumatore può sospendersi in attesa finché il buffer non è pieno (o comunque finché non c'è almeno un elemento), senza consumare risorse CPU
	- Quando il produttore aggiunge un elemento al buffer, invia un segnale                                (`pthread_cond_signal`) che risveglia il consumatore.

| <center><font color="#d83931">Thread Call</font></center> | <font color="#d83931"><center>Description</center></font>                                                                                                                                                       |
| --------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <center>**`pthread_cond_init`**</center>                  | Inizializza una variabile di condizione (`pthread_cond_t`) per consentire la sincronizzazione tra thread. La variabile di condizione viene associata a un mutex per coordinare l’accesso a risorse condivise.   |
| <center>**`pthread_cond_destroy`**</center>               | Distrugge una variabile di condizione, liberando le risorse associate. Deve essere chiamata solo quando non ci sono thread in attesa sulla condizione.                                                          |
| <center>**`pthread_cond_wait`**</center>                  | Blocca il thread chiamante in attesa della segnalazione di una condizione. Il thread deve detenere un lock sul mutex associato, che viene rilasciato automaticamente durante l’attesa e riacquisito al termine. |
| <center>**`pthread_cond_signal`**</center>                | Risveglia uno dei thread in attesa sulla variabile di condizione. Se nessun thread è in attesa, la segnalazione viene persa. Questo è utile per notificare il cambiamento di stato di una risorsa condivisa.    |
| <center>**`pthread_cond_broadcast`**</center>             | Risveglia tutti i thread in attesa sulla variabile di condizione. Questo è utile quando un evento deve notificare più thread contemporaneamente, ad esempio, quando una risorsa diventa disponibile per tutti.  |

###### SENZA `pthread_cond_wait` USI IL BUSY-WAITING
```c
pthread_mutex_lock(&mutex);
while (buffer == 0) { // Controllo continuo della condizione (inefficiente)
    pthread_mutex_unlock(&mutex);
    usleep(1000); // Ritardo per ridurre il busy-waiting (non ottimale)
    pthread_mutex_lock(&mutex);
}
consume(buffer);
pthread_mutex_unlock(&mutex);
```
Il consumatore prende il `mutex`; entra nel `while` e se il buffer è vuoto rilascia il `mutex`, si mette a dormire per un po' e poi lo riprende e NEL CASO ricomincia il ciclo 
Il consumatore controlla continuamente se `buffer == 0`, sprecando risorse CPU.

###### CON `pthread_cond_wait` È TUTTO PIÙ BELLO
```c
pthread_mutex_lock(&mutex);
while (buffer == 0) {
    // Attesa passiva finché il buffer non è pieno
    pthread_cond_wait(&cond, &mutex)
}
consume(buffer);
pthread_mutex_unlock(&mutex);
```
Il consumatore si sospende senza consumare CPU finché il produttore non segnala                          (`pthread_cond_signal`) che il buffer non è più vuoto.

###### ESEMPIO DEL PROF
```c
for (i = 1; i < = MAX; i++) {
    pthread_mutex_lock(&the_mutex);
	
    while (buffer != 0) {
        pthread_cond_wait(&condp, &the_mutex);
    }
	
    // ... altre operazioni sulla risorsa condivisa ...
}
```
- **Protezione della risorsa condivisa**: `pthread_mutex_lock` assicura che solo un thread alla volta acceda alla risorsa condivisa (in questo caso il buffer)
	
- **Attesa condizionale**: Quando un thread chiama `pthread_cond_wait` avvengono due operazioni atomiche. Il thread:
	- Rilascia il mutex
	- Mette il thread in uno stato di attesa sulla variabile condizionale
	
- Quindi se un produttore detiene il mutex, se viene messo in attesa lo lascia temporaneamente agli altri
	- in questo modo il consumatore (o un altro thread) può acquisire il mutex, fare le sue cose e mandare un segnale alla variabile condizionale usando `pthread_cond_signal` e SE PUÒ il produttore lo riprende per fare le sue cose


>[!tip] COMODITÀ DELLE VARIABILI CONDIZIONALI
>- A differenza dei semafori, le variabili condizionali **non accumulano segnali**
>- Se un `signal` viene inviato ma nessun processo è in attesa, il segnale viene perso.

---

## I MONITOR
La comunicazione tra processi tramite mutex e semafori non è semplice.
Per questo Hansen e Hoare proposero il concetto di "**monitor**".

Un **monitor** è un **meccanismo di sincronizzazione** ad alto livello progettato per facilitare la gestione della **mutua esclusione** e della **sincronizzazione** tra processi o thread.

Possiamo considerarlo come un "contenitore logico" che combina:
  - Dati condivisi che devono essere protetti (**variabili condivise**).
 - Operazioni sicure per manipolare quei dati (**procedure**).
 - Meccanismi di sincronizzazione (**wait** e **signal** con mutua esclusione garantita automaticamente). 

In pratica puoi vederlo come *IL COMPORTAMENTO DEL CODICE CHE SCRIVI*.

>[!tip] Linguaggi come `Java` supportano i monitor


###### PSEUDOCODICE DI MONITOR PER PRODUTTORE-CONSUMATORE
```scss
monitor example
    integer i;
    condition c;
	
    procedure producer();
        ...
    end;
	
    procedure consumer();
        ...
    end;

end monitor;
```

#### Monitor: Produttore-Consumatore
```c
monitor ProdCons {
    condition full, empty;     // condizioni di buffer pieno e vuoto
    int count = 0;             // elementi presenti nel buffer
	
    void enter(int item) {     // PRODUTTORE
        if (count == N) {      // se il buffer è pieno
	        wait(full);        // si mette in attesa di un signal(full)
        }
        insert_item(item);     // inserisce l'item
        count++;               // incrementa il conteggio degli elementi
        if (count == 1) {      // se l'item inserito è il primo
	        signal(empty);     // manda un segnale al consumatore
	    }
    }
	
    void remove(int *item) {   // CONSUMATORE
        if (count == 0) {      // se il buffer è vuoto
	        wait(empty);       // si mette in attesa di un signal(empty)
        }
        *item = remove_item(); // rimuove un item dal buffer
        count--;               // crescrementa il conteggio degli elementi
        if (count == N-1) {    // se ha rimosso un item
	        signal(full);      // manda un segnale al produttore
	    }
    }
}
```
##### COSA SUCCEDE
***PRODUTTORE***
- Il produttore vede se il buffer è pieno (`count == N`) e se lo è si mette in attesa (`wait(full)`) che il consumatore invii un `signal(full)`, banalmente possiamo vederli così
	- `wait(full)`, il produttore dice "*CAZZO DEVO ASPETTARE PERCHÉ IL BUFFER È PIENO*"
	- `signal(full)`, il consumatore dice "*FRA IL BUFFER NON È PIÙ PIENO*"
	
- Se non è pieno inserisce un item (`insert_item(item)`) e incrementa il conteggio (`count++`)
	
- Se l'elemento inserito è il primo (`count == 1`), invia un segnale al consumatore                          (`signal(empty)`), anche qui possiamo vederla tipo
	- `wait(empty)`, il consumatore dice "*DIO, DEVO ASPETTARE PERCHÉ IL BUFFER È VUOTO*"
	- `signal(empty)`, il produttore dice "*COMPARE CHILL, IL BUFFER NON È PIÙ VUOTO*"

>[!question]- Perché mettiamo `if (count == 1)`?
>Perché quando il produttore ha inserito il primissimo elemento vuol dire che il buffer non è più vuoto.
>Sveglio TUTTI i consumatori.
>Possono accadere due cose:
>1. un consumatore è velocissimo, prende subito elemento; il buffer è di nuovo vuoto (`count = 0`) e tutti i consumatori tornano a dormire.
>	- DEVO RISVEGLIARLI DI NUOVO, quindi grazie a `count == 1` posso risvegliarli
>2. i consumatori sono lenti e il produttore mette altri elementi sul buffer
>	- NON DEVO SVEGLIARLI perché sono tutti già svegli e si stanno dirigendo verso il buffer


***CONSUMATORE***
- Il consumatore vede se il buffer è vuoto (`count == 0`) e se lo è si mette in attesa che il produttore invii un `signal(empty)`
	
- Se non è vuoto rimuove un item (`remove_item`) e decrementa il conteggio (`count - -`) 
	
- Se l'elemento rimosso è l'ultimo (`count == N-1`), invia un segnale al produttore (`signal(full)`) 

>[!question] Perché mettiamo `if (count == N-1)`? Arrivaci da solo 


#### Funzione produttore
```c
void producer() {
    int item;
    while (TRUE) {
        item = produce_item();
        ProdCons.enter(item);
    }
}
```

#### Funzione consumatore
```c
void consumer() {
    int item;
    while (TRUE) {
        ProdCons.remove(&item);
        consume_item(item);
    }
}
```


>[!example]- Differenze tra `sleep/wakeup` e `wait/signal`
>`sleep/wakeup`
>- meccanismi più primitivi con il problema della race condition (il processo A vuole svegliare B ma B sta già sotto le coperte)
>
>`wait/signal`
>- Sono protetti da **mutua esclusione** all'interno del monitor


>[!tip]- Perché sembra che il monitor sia solo il codice?
>
Questa sensazione deriva dal fatto che, nei linguaggi come **C**, non esiste un costrutto "monitor" nativo. Scrivendo codice come sopra, **tu definisci la logica** di un monitor, ma il compilatore **non lo riconosce automaticamente**. Devi implementare tu i meccanismi di mutua esclusione e sincronizzazione usando primitive come semafori o mutex.
>
Invece, in linguaggi come **Java**, i monitor sono **costrutti nativi**.


---

## SCAMBI DI MESSAGGI
Lo scambio di messaggi è una tecnica di comunicazione tra processi che non utilizza memoria condivisa, e si basa su due primitive:
- `send`, che invia un messaggio ad un altro processo
- `receive`, che riceve un messaggio da un altro processo

È molto utile nei sistemi distribuiti, dove i processi non condividono memoria e comunicano tramite rete.
#### PROBLEMI
- **Messaggi persi** 
	- I messaggi possono essere persi durante la trasmissione (es. problemi di rete)
	
- **Necessità di acknowledgment**
	- Serve un meccanismo per confermare che un messaggio è stato ricevuto correttamente
	
- **Autenticazione**
	- Bisogna verificare che il mittente del messaggio sia la persona corretta
	
- **Denominazione dei processi**
	- I processi devono sapere a chi inviare e da chi ricevere


### Scambio di messaggi: Produttore-Consumatore
Questa è una soluzione al classico problema ma senza memoria condivisa e usando solo messaggi.
###### FUNZIONAMENTO
- Si utilizzano `N messaggi`, simili agli `N posti` del buffer nella memoria condivisa
	- Il consumatore invia al produttore `N messaggi` **vuoti** (uno alla volta)
	- Il produttore prende un messaggio vuoto, **lo riempie e lo invia**
	- Il consumatore legge il messaggio, **lo elabora e lo riinvia (vuoto)**

In questo modo il numero totale di messaggi rimane costante e gestito dal SO.
Questa soluzione garantisce efficienza.

###### CODICE
***PRODUTTORE***
```c
void producer() {
    int item;
    message msg;
	
    while (TRUE) {
        item = produce_item();       // produce l'item
        receive(consumer, &msg);     // riceve dal consumatore il messaggio (vuoto)
        build_message(&msg, item);   // costruisce il messaggio inserendo l'item
        send(consumer, &msg);        // invia al consumatore il messaggio (pieno)
    }
}
```

***CONSUMATORE***
```c
#define N 100

void consumer() {
    int item, i;
    message msg;
	
    for (i = 0; i < N; i++) {
        send(producer, &msg);      // invia al produttore un messaggio vuoto (per 
                                   // volta)
    }
	
    while (TRUE) {
        receive(producer, &msg);   // riceve dal produttore il messaggio (pieno)
        item = extract_item();     // estrare l'item dal messaggio
        send(producer, &msg);      // riinvia al produttore il messaggio (vuoto)
        consume_item(item);        // consuma l'item
    }
}

```

>[!warning] N.B.: Viene eseguito prima il `ciclo for` nel consumatore e poi i due cicli `while`
>

#### Problematiche
- Se il produttore è più veloce, tutti i messaggi saranno pieni e quindi deve aspettare
- Se il consumatore è più veloce, tutti i messaggi saranno vuoti e quindi deve aspettare

#### Indirizzamento dei messaggi
Quando i messaggi devono essere scambiati tra processi diversi, è necessario un meccanismo per identificare chi invia a chi riceve.

Due soluzioni possibili
- Ogni processo ha un **indirizzo univoco** che permette di identificare a chi inviare e da chi ricevere
- Invece di inviare direttamente il messaggio al destinatario, questo viene inviato a una **Mailbox** (una sorta di buffer)
	- la mailbox funge da intermediari che conservano il messaggio fino a quando il destinatario è pronto per riceverlo
	- in questo modo il mittente non si blocca e continua a fare il suo lavoro

#### Applicazioni
- Scambio di messaggi usato in programmazione parallela
- **MPI** (Message Passing Interface) è un esempio usato in elaborazioni scientifiche


### BARRIERE
Le barriere sono utilizzare per sincronizzare processi o thread (**strettamente dipendenti**) in calcoli paralleli e servono a garantire che i processi avanzino insieme tra diverse fasi di un calcolo o un operazione.

In pratica funziona così
- Se un processo arriva alla barriera prima degli altri, li **aspetta**
- Quando tutti i processi sono arrivati alla barriera, **avanzano insieme**
![[Pasted image 20241114111924.png]]


---

## INVERSIONE DELLE PRIOTITÀ
![[Pasted image 20241114112324.png]]
###### PROBLEMA
- Il **thread di bassa priorità** aveva la risorsa condivisa (bloccata dal mutex) ma non la CPU
- Il **thread di alta priorità** necessitava della risorsa condivisa ma era bloccata
- Il **thread di media priorità** aveva la CPU (perché ha più priorità del thread con bassa priorità)
###### RISULTATO
Il **thread di alta priorità** è rimasto bloccato (anche se di norma ha priorità massima) e quindi attivava un riavvio del sistema.

Questo caso viene descritto come **inversione delle priorità** (in pratica sono tutte sballate).

###### SOLUZIONE
La NASA ha risolto il problema introducendo il **protocollo di eredità delle priorità** (*Priority Inheritance*)
- quando un **thread di alta priorità** attende una risorsa bloccata da un **thread di bassa priorità**, il sistema "eleva" temporaneamente la sua priorità al livello del thread bloccante (poteva succedere anche con priorità media, ecco perché `livello del thread bloccante`);
- in questo modo il **thread di bassa priorità** può completare rapidamente il lavoro e rilasciare il *mutex*, consentendo al **thread di alta priorità** di procedere;
- una volta completato il suo lavoro, il **thread di priorità bassa** torna alla sua priorità originale.

>[!example]- Una versione semplificata
>IL PC È UNO SOLO
>- **Andrea** (alta priorità) deve giocare a GOW
>- **Luca** (bassa priorità) è nella lobby di fortnite
>- **Samuele** (priorità media) sta vedendo un ep. di Blue Lock sul Tablet, ma sta continuamente interrompendo Luca chiedendogli di fargli vedere le skin che ha nel suo armadietto
>
>RISULTATO: 
>- Luca non riesce ad uscire dal gioco
>- Andrea, che avrebbe priorità alta, aspetta inutilmente
>
>SOLUZIONE CON ***PROTOCOLLO DI EREDITÀ DELLE PRIORITÀ***
>- Quando Andrea aspetta Luca, Luca **eredita temporaneamente** la priorità di Andrea
>- Luca può andare su `quit` per poi uscire, ignorando completamente il povero Samuele che voleva solo vedere le skin 😔
>- Una volta uscito dal gioco, Luca torna alla sua priorità normale (godo coglione)



## READ-COPY-UPDATE
##### OBIETTIVO di base
- Permettere **accessi concorrenti senza blocchi** tra lettori e scrittori.
- Ridurre i costi di sincronizzazione (come mutex o semafori) per migliorare le prestazioni in ambienti multithread.
##### Problema
- Senza una gestione attenta, lettori e scrittori possono accedere simultaneamente a strutture di dati, portando a dei casini.

##### PRINCIPIO DI READ-COPY-UPDATE
L'idea base è **separare i lettori dagli scrittori** attraverso un meccanismo che consente a entrambi di lavorare senza interferenze dirette.
##### Principio di base
1. **Read (lettura):**
    - I lettori possono accedere ai dati **senza lock**.
    - Non c'è rischio che i lettori leggano dati incoerenti, perché vedono solo versioni complete della struttura.
    
2. **Copy (copia):**
    - Quando uno scrittore deve aggiornare i dati, crea una **copia della struttura** da modificare.
    - La copia viene modificata senza interferire con i lettori che stanno usando la versione attuale.
	
3. **Update (aggiorna):**
    - Una volta completata la modifica, lo scrittore **sostituisce la vecchia versione con la nuova**.
    - I nuovi lettori iniziano a usare la nuova versione, mentre quelli già attivi continuano a leggere la vecchia. NON SI AVRÀ MAI UN MIX.

###### AGGIUNGERE UN NODO
![[Pasted image 20241114115954.png]]

###### TOGLIERE NODI
![[Pasted image 20241114120005.png]]
#### Problema: Quando liberare B e D?
- In un sistema RCU, le vecchie versioni di una struttura (come `B` e `D`) non possono essere liberate immediatamente dopo l'aggiornamento.
	- Questo perché potrebbero esserci ancora lettori che stanno accedendo alla vecchia versione.
- Il problema diventa: **Come sapere quando è sicuro liberare la memoria?**
#### Soluzione RCU: Grace Period
Il **Grace Period** è un meccanismo utilizzato per determinare quando una vecchia versione di dati può essere liberata in sicurezza.
- Si ha un intervallo di tempo durante il quale si aspetta che **tutti i lettori** abbiano completato l'accesso alla vecchia versione dei dati.
- Durante questo periodo, i thread che leggono **non si bloccano** e **non vanno in sleep**, quindi non interrompono l'esecuzione.