 >[!lemma] PROCESSO
 >Istanza di un programma in esecuzione, con il proprio spazio di memoria isolato, con le risorse necessarie e uno stato che ne determina la posizione all'interno di un sistema operativo.
 
 

Il sistema operativo deve essere in grado di:
- ***estrarre*** le risorse
- ***contabilizzarle***
- ***limitarle*** (concedere il giusto necessario ad ogni processo)

Il sistema operativo mantiene informazioni sulle risorse e sullo stato interno di ogni singolo processo del sistema, e tutte queste informazioni sono contenute in una tabella.

Quando abbiamo più processi da dover eseguire; il SO, tramite la CPU, è in grado di passare da un processo all'altro in maniera molto repentina, dando l'idea che questi avvengano in ***parallelo***.
## Modello di un processo
- Ogni processo ha una **porzione specifica di memoria assegnata**.
- Le frecce indicano il **process switch**, ossia il passaggio da un processo ad un altro. In questo modo noi abbiamo l'illusione che tutti i processi vengano svolti simultaneamente ma in realtà c'è un continuo switch repentino gestito dalla CPU.
- In questo caso il **PC** è uno solo.
![[content/Zphoto/PHOTO SO E RETI (VECCHIE)/Pasted image 20241101145842.png|center]]

La CPU, per poter switchare da un processo all'altro ha bisogno di salvarsi il PC e lo stato del processo corrente (quello che sta per finire) e ripristinarlo quando vuole riprenderlo.
Così tutti i processi possono progredire ma ***solo uno è attivo in un dato momento***.
![[content/Zphoto/PHOTO SO E RETI (VECCHIE)/Pasted image 20241101151131.png]]

In linea di principio tutti i processi sono indipendenti e tra loro la memoria è separata, quindi servono dei meccanismi per farli interagire tra loro e si va a creare una sorta di gerarchia (Comando `ps fux`).

## Gerarchie di processi
Il sistema operativo all'inizio crea un solo processo chiamato `init`, che rimane attivo fino allo spegnimento della macchina.
Questo processo avrà a cascata tutti i sottoprocessi, creati in modo indipendente.
![[content/Zphoto/PHOTO SO E RETI (VECCHIE)/Pasted image 20241101154207.png|center|200]]


## Creazione di un processo
Quattro sono gli eventi principali per generare un processo (OGNUNO A SÉ STANTE):
1. **Inizializzazione del sistema (`init`)**
    - All'avvio della macchina, il sistema operativo crea il processo **`init`**, il primo processo in assoluto e padre di tutti gli altri.
    - `init` rimane in esecuzione fino allo spegnimento del sistema e funge da radice dell’albero gerarchico dei processi.
2. **Chiamata di sistema `fork()`**
    - Un processo padre può generare un processo figlio tramite la chiamata di sistema **`fork()`**creando un nuovo processo che inizialmente condivide lo stesso spazio di memoria del padre.
3. **Richiesta esplicita dell'utente tramite shell o script**
    - Un utente può avviare un processo manualmente eseguendo un comando nella shell (`bash`, `zsh`, `sh`).
4. **Esecuzione di un processo in modalità batch**
    - Alcuni processi possono essere avviati in **modalità batch**, ovvero come lavori in background che non richiedono interazione diretta con l’utente.

## Termine di un processo
Un processo può terminare in diversi modi, suddivisi in due categorie principali:
**1. Terminazione volontaria**
- **Uscita normale:** il processo termina dopo aver completato la sua esecuzione con successo.
    - Esempio: un programma che stampa i numeri da 1 a 10 e poi si chiude.
- **Uscita a seguito di un errore gestito:** il processo rileva un errore da cui non può recuperare e termina.
    - Esempio: apertura di un file non esistente con un errore gestito.

 **2. Terminazione involontaria**
- **Errore fatale:** il processo tenta di eseguire un'operazione non consentita (es. accesso a una memoria non allocata).
    - Esempio: tentativo di scrivere in un’area di memoria protetta provoca un **segfault (`Segmentation fault`)**.
- **Uccisione da parte di un altro processo (`kill`)**
    - Un processo può terminare un altro processo inviando un segnale con il comando `kill`.


## Process Management
SONO TUTTE CHIAMATE DI SISTEMA
- `FORK`:  il comando `fork()` è una chiamata di sistema che permette a un processo (detto processo padre) di creare una copia esatta di se stesso, creando così un nuovo processo (detto processo figlio), il quale ha una copia del contesto del processo padre (inclusi i file aperti e l'ambiente). Tuttavia, il figlio ha un proprio spazio di indirizzamento, quindi le modifiche alle variabili fatte dal figlio non influenzano il processo padre; e anche un PID diverso

- `EXECL`: esegue di nuovo un processo

- `EXIT`: causa la terminazione volontaria del processo

- `KILL`: invia un segnale a un processo (o a un gruppo)
	- il segnale, senza dettagli, termina il processo


## Gli stati di un processo
- **Running** / Esecuzione (sta utilizzando la CPU in quel momento)
	- es. sto guidando

- **Ready** / Pronto (eseguibile ma non ancora in esecuzione)
	- es. la macchina è pronta, ho inserito la chiavi e devo solo accenderla

- **Blocked** / Bloccato (non può essere eseguito fino a quando non si verifica un evento esterno)
	- es. non ho la benzina oppure non ho inserito le chiavi

![[content/Zphoto/PHOTO SO E RETI (VECCHIE)/Pasted image 20241101162917.png|center]]

La gestione ottimale dei processi avviene tramite lo scheduler.


## Informazioni associate a un processo
Un singolo processo ha queste informazioni:
- **ID** (PID), **Utente** (UIP), **Gruppo** (GID)
- Spazio degli indirizzi di memoria
- Registri hardware (es. PC)
- File aperti
- **Segnali** (Signal)
- **Interrupt**

#### Signal vs Interrupt
Sia gli **Interrupt** che i **Signal** sono meccanismi utilizzati per gestire eventi **asincroni**, ovvero eventi che si verificano **senza che il processo li abbia previsti**. La differenza principale è la loro origine e come vengono gestiti.
- ***INTERRUPTS***
	Gli **interrupt** sono eventi **hardware** che avvisano il sistema operativo che un dispositivo ha bisogno di attenzione. Quando un interrupt si verifica, il sistema operativo **sospende temporaneamente il processo in esecuzione** e risponde alla richiesta dell'hardware.
	
	CARATTERISTICHE:
	- **Hanno alta priorità** e possono interrompere anche i processi più importanti.
	- **Sono gestiti da routine speciali (ISR)**, che rispondono velocemente all'evento.


- ***SIGNALS***
	I **signal**, invece, sono eventi **software** inviati da un processo a un altro o dal sistema operativo a un processo. Vengono usati per notificare condizioni particolari, come errori, terminazioni, o richieste di riavvio.
	
	Caratteristiche:
	- **Possono essere gestiti da un Signal Handler**: una funzione che il programmatore può definire per reagire in modo personalizzato.
	- **Sono asincroni**, ma possono essere **gestiti in modo sincrono** (il processo può controllare i segnali in momenti specifici anziché reagire immediatamente).

>[!lemma]- SINCRONO E ASINCRONO
>- SINCRONO
>	Ogni tot di tempo avviene qualcosa / lo scheduler controlla qualcosa
>
>- ASINCRONO
>	Un segnale può arrivare e può essere gestito in qualsiasi momento


## Implementazione dei processi
![[content/Zphoto/PHOTO SO E RETI (VECCHIE)/Pasted image 20250121113205.png]]
Quando un dispositivo (es. tastiera) genera un interrupt:
- La **CPU ferma il processo attuale** e salva il **PC (Program Counter)**, ovvero l'indirizzo dell'istruzione in esecuzione.
	- I registri della CPU (che contengono variabili, dati, contatori) vengono **salvati nello stack del kernel**.
- **Il vettore di interrupt** viene consultato per determinare quale routine di gestione deve essere eseguita.
	- il **vettore di interrupt** punta alla giusta ISR (Interrupt Service Routine).
	- Questa routine, spesso scritta in **assembly**, **salva lo stato della CPU** e prepara uno **stack temporaneo**.
- L’ISR poi chiama una funzione **scritta in C** per eseguire l'operazione necessaria (es. leggere il tasto premuto e metterlo in un buffer).

Una volta terminato il servizio dell’interrupt:
- **Lo scheduler del SO decide quale processo deve essere eseguito**.
	- Se il processo interrotto ha ancora tempo CPU disponibile, **torna in esecuzione**.
	- Se un altro processo ha una priorità più alta, il sistema **effettua un context switch** per eseguire un altro processo.
- Dopo che il servizio di interrupt ha finito, il sistema operativo **ripristina i registri della CPU** dallo stack.
- Il processo selezionato dallo scheduler riprende da dove era stato interrotto.

Ogni volta che si verifica un'interruzione, lo scheduler ottiene il controllo (funge da mediatore), infatti un processo non può cedere la CPU ad un altro processo (context switch) senza passare per lo scheduler.


## Tipologie di segnali
- **Hardware-induced**:
	- Segnali causati da eventi hardware, come `SIGKILL`, che indica al sistema di terminare immediatamente un processo.

- **Software-induced**:
	- Segnali generati da eventi software, come `SIGQUIT` o `SIGPIPE`. Ad esempio, `SIGQUIT` può essere inviato quando l'utente preme una combinazione di tasti speciale per terminare un programma.
#### Azioni Possibili
I segnali possono avere diverse azioni predefinite
- **Term**: termina il processo.
- **Ign**: ignora il segnale.
- **Core**: termina il processo e genera un file di dump della memoria (utile per il debugging).
	- un **file di dump** è una copia dei dati presenti nella memoria di un processo al momento di un errore o crash.
- **Stop**: sospende l'esecuzione del processo.
- **Cont**: continua l'esecuzione di un processo precedentemente sospeso.

#### Gestione (Catching) dei Segnali
1. **Registrazione del Gestore del Segnale**:
    - Un processo può registrare una funzione speciale, detta **gestore del segnale** o handler, per gestire i segnali in modo personalizzato.

2. **Invio e Esecuzione dell'Handler**:
    - Quando il sistema operativo invia un segnale a un processo, consente al processo di eseguire l’handler specifico registrato per quel segnale.

3. **Salvataggio/Ripristino del Contesto**:
    - Quando il segnale viene gestito, il sistema salva il contesto attuale (lo stato del processo), esegue l’handler, e poi ripristina il contesto originale per permettere al processo di continuare da dove era stato interrotto.

###### GESTIRE IL SEGNALE INDOTTO DA CTRL + C
![[content/Zphoto/PHOTO SO E RETI (VECCHIE)/Pasted image 20241101190913.png|center]]
Ecco cosa succede nel pratico
- il kernel invia un segnale
- interrompe il codice in esecuzione
- salva il contesto, ossia lo stato del attuale del processo
- esegue il codice di gestione del segnale
- ripristina il contesto originale


---


## THREAD

>[!lemma] DEFINIZIONE: ***Thread***
>Un thread è l’unità di esecuzione più piccola di un processo. Un processo può essere suddiviso in più thread, che condividono lo stesso spazio di memoria del processo principale e lavorano in parallelo, migliorando l'efficienza in termini di tempo e utilizzo delle risorse.
>- 1 processo ⇒  thread in esecuzione


>[!question]- Perché consentire più thread per processo?
>**Lightweight processes (processi leggeri)**:
>- ogni thread condivide la stessa memoria e risorse del processo principale, riducendo il consumo di memoria e migliorando l'efficienza
>- Questo consente di ottenere **parallelismo** (ovvero, eseguire più operazioni contemporaneamente) in modo più efficiente in termini di spazio e tempo
>
>**Comunicazione e sincronizzazione semplici**:
>- Poiché i thread di un processo condividono la stessa area di memoria, possono comunicare e sincronizzarsi tra loro in modo più semplice rispetto ai processi separati

#### Utilizzo dei thread
![[content/Zphoto/PHOTO SO E RETI (VECCHIE)/Pasted image 20241101194201.png]]

###### Un Web server multithreaded 
![[content/Zphoto/PHOTO SO E RETI (VECCHIE)/Pasted image 20241101194253.png|center]]

#### Caratteristiche sui thread
- ogni thread sarà nello stesso spazio degli indirizzi di un singolo processo
- Gli scambi di informazioni avvengono tramite i dati condivisi tra thread
- Ogni thread ha
    - il proprio stack
    - i propri registri hardware
    - il proprio stato
- Tabella dei thread con anche la sua tabella degli interrupt
- Ciascun Thread può chiamare qualsiasi chiamata di sistema supportata dal sistema operativo per conto del processo di cui è figlio
- Ogni Thread ha i suoi elementi privati(Stack) e i suoi elementi condivisi(Variabili globali)

#### Thread in posix
<font color="#ff0000">CHIEDE A ESAME</font> ![](https://likingaxis.github.io/UNI/UNI/ANNO-2/SISTEMI-OPERATIVI/fotosop/Pasted-image-20241102104411.png) Il thread e addestrato per fare un lavoro quindi praticamente esegue una funzione tipo in c


#### Thread nello spazio utente
Un thread potrebbe essere definito o gestito nello spazio utente, oppure, qualora debbano essere eseguite chiamate di sistema più particolari, può essere gestito dal kernel.
![[content/Zphoto/PHOTO SO E RETI (VECCHIE)/Pasted image 20250121120057.png]]


>[!tip]- Approfondimento sui thread al livello utente
> 
> PRO:
> 
> - sono gestiti dal kernel come dei processi a singolo thread anche se sono più thread
> - gestiti tramite libreria e possono anche essere eseguiti da s.o. che non supportano i thread
> - Ogni processo che usa thread a livello utente necessita di una propria tabella dei thread per tracciare lo stato e altre cose
> - Non è richiesto un cambiamento di contesto completo perché sono tutti sotto lo stesso processo
> - Offrono maggiore scalabilità e personalizzazione dell’algoritmo di scheduling Contro:
> - se uno fa una chiamata di sistema bloccante tutti i Thread vengono fermati, questa cosa accade anche in caso di errori, perché vengono visti come un singolo individuo e quindi il s.o. potrebbe fermarli tutti
> - I thread nello spazio utente non hanno interrupt del clock quindi non possono fare round robin
> - Sebbene più veloci i Thread al livello utente non sono adatti per applicazioni che si bloccano spesso come i web server

>[!tip]- Approfondimento su Thread nello spazio kernel
> 
> - Il kernel che gestisce i thread elimina la necessità di avere un sistema run-time per processo
>     - per sistema run-time si intende un sistema che compila e interpreta esegue ecc… se ho tutto nel kernel non ho bisogno di avere sistemi particolari per fare chiamate di sistema perché siamo già vicini al kernel
> - Le chiamate che potrebbero bloccare un thread vengono implementate come chiamate di sistema e quindi non avrò più quei blocchi
> - Riciclo dei thread per ridurre i costi
> - Programmazione con thread richiede cautela per evitare errori

>[!tip]- Approfondimento su Thread con sistema ibrido
> 
> Alcuni sistemi effettuano un multiplexing dei thread utente su thread del kernel (praticamente sceglie chi usare) Maggiore flessibilità per i programmatori che possono scegliere quanti thread usare in spazio utente e quanti in spazio kernel Il kernel è a conoscenza solo dei suoi thread nello spazio kernel Ogni thread del kernel può gestire però i thread a livello utente anche se il kernel non li conosce ![](https://likingaxis.github.io/UNI/UNI/ANNO-2/SISTEMI-OPERATIVI/fotosop/Pasted-image-20241102111832.png)

Problemi sui thread: conflitti, sovrascrizione, problemi di implementazione anche di buffer ecc…


---

# Domande
#### **1. Modello e gestione dei processi in Linux**
<font color="#4bacc6">Si invita il candidato a fornire un'analisi dettagliata del concetto di processo in Linux, illustrandone il modello e la gestione da parte del sistema operativo. Si spieghi come il sistema operativo assegna memoria e risorse a un processo, e in che modo avviene il process switch tra processi concorrenti. Si fornisca inoltre una spiegazione del ruolo del Program Counter (PC) e della gerarchia dei processi, con particolare riferimento al processo</font> `init`.

In un sistema operativo **Linux**, un **processo** è un'istanza in esecuzione di un programma. Ogni processo dispone di un proprio **spazio di memoria isolato**, delle risorse necessarie per l’esecuzione e di un **stato** che ne determina la posizione all'interno del sistema operativo.

Il sistema operativo è responsabile della **gestione dei processi**, garantendo che ognuno abbia accesso alle risorse richieste e che non vi siano conflitti nella loro esecuzione: per poter garantire la corretta esecuzione di ognuno di essi è necessario che il SO sappia rintracciare correttamente e repentinamente tutte le risorse necessarie, e che queste vengano contabilizzare ed equamente spartite.

Infatti il SO deve riuscire a dare l'idea che più processi vengano eseguiti in parallelo tramite il "process switch", ossia il cambio di esecuzione tra processi.
Per permettere ciò, i processi, a turno, devono accedere alla CPU per poter eseguire le loro operazioni; questo passaggio viene gestito dallo scheduler, che in base ad alcuni controlli (es, tempo rimanente, priorità ecc.) sceglie quale processo deve essere eseguito.

I processi, una volta avviati, possono trovarsi in tre stati differenti:
- esecuzione
- pronto
- attesa 
In questo contesto quindi gioca un ruolo fondamentale il PC, che punta all'indirizzo della prossima istruzione da dover eseguire; quando un processo viene messo in stato di "attesa", il sistema deve salvare il PC così da poterlo riprendere in maniera corretta.

Trovandosi in un sistema in cui le gerarchie sono fondamentali, anche i processi sono categorizzati in una disposizione "ad albero", che ha come radice il processo `init`, il quale viene eseguito conseguentemente all'avvio della macchina, rimane in esecuzione fin quando il sistema non viene spento e da esso si diramano tutti gli altri processi (iniziati indipendentemente).

---

#### **2. Creazione e terminazione di un processo**
**<font color="#4bacc6">Si descrivano i meccanismi con cui un nuovo processo viene creato in Linux, includendo i seguenti eventi principali:</font>**

- <font color="#4bacc6">**Inizializzazione del sistema**</font> (`init`)
- **<font color="#4bacc6">Chiamata di sistema</font>** `fork()` <font color="#4bacc6">per la creazione di un processo figlio</font>
<font color="#4bacc6">- Richiesta esplicita dell’utente tramite shell o script</font>
<font color="#4bacc6">- Esecuzione di un processo in modalità batch</font>

**<font color="#4bacc6">Si illustrino inoltre le diverse modalità con cui un processo può terminare, distinguendo tra terminazione volontaria e involontaria. Si fornisca un’analisi dell’uso del comando</font> `kill` <font color="#4bacc6">e del segnale generato da</font> `CTRL + C` <font color="#4bacc6">per la chiusura di un processo.</font>**

In un sistema operativo **Linux**, un processo può essere creato attraverso diversi meccanismi, ognuno dei quali dipende dal contesto di esecuzione. Il sistema operativo deve gestire l’avvio, l’esecuzione e l’eventuale terminazione dei processi, allocando in modo efficiente le risorse disponibili.

Esistono quattro principali eventi attraverso i quali un nuovo processo può essere generato:
1. **Inizializzazione del sistema (`init`)**
    - All'avvio della macchina, il sistema operativo crea il processo **`init`**, il primo processo in assoluto e padre di tutti gli altri.
    - `init` rimane in esecuzione fino allo spegnimento del sistema e funge da radice dell’albero gerarchico dei processi.
2. **Chiamata di sistema `fork()`**
    - Un processo padre può generare un processo figlio tramite la chiamata di sistema **`fork()`**, creando un nuovo processo che inizialmente condivide lo stesso spazio di memoria del padre.
3. **Richiesta esplicita dell'utente tramite shell o script**
    - Un utente può avviare un processo manualmente eseguendo un comando nella shell (`bash`, `zsh`, `sh`).
4. **Esecuzione di un processo in modalità batch**
    - Alcuni processi possono essere avviati in **modalità batch**, ovvero come lavori in background che non richiedono interazione diretta con l’utente.


Un processo può terminare in diversi modi, suddivisi in due categorie principali:
**1. Terminazione volontaria**
- **Uscita normale:** il processo termina dopo aver completato la sua esecuzione con successo.
    - Esempio: un programma che stampa i numeri da 1 a 10 e poi si chiude.
- **Uscita a seguito di un errore gestito:** il processo rileva un errore da cui non può recuperare e termina.
    - Esempio: apertura di un file non esistente con un errore gestito.

 **2. Terminazione involontaria**
- **Errore fatale:** il processo tenta di eseguire un'operazione non consentita (es. accesso a una memoria non allocata).
    - Esempio: tentativo di scrivere in un’area di memoria protetta provoca un **segfault (`Segmentation fault`)**.
- **Uccisione da parte di un altro processo (`kill`)**
    - Un processo può terminare un altro processo inviando un segnale con il comando `kill`.

È utile soffermarsi su questo ultimo punto e analizzare la gestione da parte del sistema del segnale `KILL`.
Tutti i segnali sono gestiti da un signalHendler, il meccanismo che permette ai processi di gestire determinati segnali prima di terminare.
Un processo invia un segnale di `KILL`, il signalHendler inizia la routine per la gestione di tale segnale e la esegue sul processo indicato .

---

#### **3. Stati e scheduling dei processi**
**<font color="#4bacc6">Si chiede al candidato di analizzare i diversi stati di un processo in Linux, evidenziando le transizioni tra:</font>**

- **Stato Running** (esecuzione attiva)
- **Stato Ready** (pronto per essere eseguito)
- **Stato Blocked** (in attesa di un evento esterno)

**<font color="#4bacc6">Si spieghi inoltre il ruolo dello scheduler nella gestione ottimale dei processi e si descriva il processo di</font> <font color="#4bacc6">context switch</font>**, **<font color="#4bacc6">evidenziando come il sistema operativo salva e ripristina lo stato di un processo durante lo switch.</font>**

In un sistema operativo **Linux**, ogni processo attraversa diversi **stati di esecuzione**, determinati dalla disponibilità delle risorse e dalle politiche di gestione adottate dallo scheduler. Poiché la CPU può eseguire un solo processo alla volta, il sistema deve garantire un meccanismo efficiente per la gestione della concorrenza, assicurando che i processi vengano eseguiti in modo equo e ottimizzato.
Per permettere ciò LINUX utilizza un modello a stati
- IN ESECUZIONE, il processo ha tutte le risorse necessarie e sta venendo eseguito
- PRONTO, il processo ha tutte le risorse necessarie ma non è il processo attivo; questo può voler dire che il processo è stato sospeso oppure che ha ottenuto la risorsa necessaria troppo tardi
- BLOCCATO, il processo non ha tutte le risorse necessaria e quindi non può essere eseguito

I processi, per poter eseguire le loro operazione devono usufruire della CPU, che quindi viene continuamente scambiata tra i singoli processi. Questo "scambio" viene gestito dallo scheduler, il quale ha il compito di scegliere quale processo dover eseguire nella fase denominata context switch.
In questa fase è necessario che il SO salvi lo stato di un processo (qualora questo venisse sospeso) per poterlo riprendere in totale sicurezza.

---

#### **4. Differenza tra segnali e interrupt in Linux**
**<font color="#4bacc6">Si invita il candidato a fornire una dettagliata analisi delle differenze tra segnali</font> (`signals`) <font color="#4bacc6">e interrupt</font> (`interrupts`) <font color="#4bacc6">nei sistemi Linux. Si chiarisca il ruolo degli interrupt come eventi generati dall’hardware e la loro gestione tramite ISR (Interrupt Service Routine). Si illustri inoltre come i segnali software vengono utilizzati per la comunicazione tra processi, fornendo esempi pratici di segnali come</font> `SIGKILL`<font color="#4bacc6"> e </font>`SIGQUIT`.**

In un sistema operativo **Linux**, gli **interrupt** e i **segnali (signals)** sono meccanismi utilizzati per gestire eventi asincroni che influenzano l’esecuzione dei processi. La differenza tra i due sta nella loro origine e nel modo in cui vengono gestiti

Gli interrupt sono eventi hardware, che notificano al sistema che un dispositivo ha bisogno di attenzione. Sono eventi con priorità molto alta, al punto che il SO può interrompere il processo corrente per gestire questi interrupt.
La loro gestione avviene tramite una ISR (Interrupt Service Routine), in cui sono contenute tutte le informazioni utili al fine di gestire correttamente l'evento.
Più nel dettaglio, all'arrivo di un interrupt viene seguito uno scheda mi operazioni ben precise
- viene salvato lo stato corrente del processo
- viene consultato il vettore di interrupt, una tabella in cui sono inseriti tutti i puntatori alle ISR; da qui di va a selezionare la routine necessaria
- viene poi eseguita la routine (scritta in C)
- lo scheduler sceglie quale processo deve essere eseguito
- finita la routine viene ristabilito lo stato del processo precedente all'interrupt

I segnali invece sono eventi di natura software, utili per la comunicazione tra processi.
Vengono gestiti tramite un interrupt Handler, un meccanismo creato dal programmatore stesso e, nonostante siano eventi asincroni, possono essere gestiti in modo sincrono.
All'avvio del programma, viene salvata la funzione di gestione del segnale, in questo modo all'arrivo dello stesso il SO è in grado di gestirlo al meglio; anche in questo caso viene salvato lo stato del processo per poi essere ripreso.
Questi segnali possono essere di due tipologie
- Hardware-induced, come `SIGKILL`
- Software-induced, come `SIGQUIT` o `SIGPIPE`



---

#### **5. Thread e multitasking in Linux**
**<font color="#4bacc6">Si chiede al candidato di fornire una spiegazione dettagliata del concetto di thread in Linux, distinguendolo dal processo tradizionale. Si analizzi il vantaggio dell’uso dei thread per migliorare l’efficienza del multitasking e si descrivano i seguenti concetti:</font>**

- **Processi multi-threaded e parallelismo**
- **Condivisione di memoria tra thread dello stesso processo**
- **Gestione dei thread da parte del sistema operativo**

Quando si parla di thread, si fa riferimento alla frammentazione più piccola di un processo. Questo infatti può essere suddiviso in tanti piccoli thread, ognuno dei quali condivide lo stesso spazio di memoria dedicato al processo.
Il concetto di thread risulta estremamente utile per quando riguarda il miglioramento delle performance, sia a livello spaziale che temporale; i thread infatti possono essere eseguiti in parallelo e, condividendo lo stesso spazio di memoria, possono comunicare e sincronizzarsi tra di loro, rendendo così più efficiente l'esecuzione del lavoro prestabilito. 

---

#### **6. Chiamate di sistema per la gestione dei processi**
**Si invitano i candidati a descrivere il funzionamento delle principali chiamate di sistema utilizzate per la gestione dei processi in Linux, evidenziando la loro funzione e i contesti di utilizzo:**

- **`fork()`** – creazione di un processo figlio
- **`execl()`** – esecuzione di un nuovo programma nel contesto di un processo esistente
- **`exit()`** – terminazione di un processo
- **`kill()`** – invio di un segnale a un processo

**Si illustri inoltre come il sistema operativo Linux gestisce la transizione tra processi e quali meccanismi adotta per garantire la sicurezza e l’isolamento dei processi tra loro.**

All'interno di un sistema LINUX, sono presenti quattro chiamate di sistema fondamentali utilizzate per la gestione dei processi, ognuna con un compito ben preciso.
- `fork()` viene utilizzata quando un processo padre vuole creare un processo figlio; inizialmente quest'ultimo si troverà nello stesso spazio di indirizzi del padre ma poi diventerà indipendente
	
- `execl()` è la chiamata di sistema incaricata di eseguire la linea di comando digitata su terminale, da qui il nome EXEcute Command Line; bisogna specificare il path dell'operazione che si vuole eseguire e lo stream su cui si vuole inviare il risultato
	
- `exit()`permette ad un processo di terminare; NB. deve essere chiamata dal processo stesso

- `kill()` viene inviato da un processo per farne terminare un altro

