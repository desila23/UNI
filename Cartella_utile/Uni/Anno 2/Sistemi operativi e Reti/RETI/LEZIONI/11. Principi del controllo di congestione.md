### Congestione di rete
La congestione si verifica quanto troppo dispositivi inviano dati velocemente e la rete non riesce a gestire la quantit√† di traffico elevata (es. i router hanno buffer limitati e se ricevono troppi dati iniziano a scartare i pacchetti).

Come abbiamo detto la scorsa volta, quando un pacchetto viene perso TCP lo ritrasmette.
Ma attenzione! üëá
	La ritrasmissione risolve solo il SINTOMO (perdita) e non l'effettiva CAUSA (la rete in sovraccarico).

E senza il controllo di congestione 
- pi√π pacchetti in coda -> pi√π congestione -> pi√π perdite -> pi√π ritrasmissioni

### Tre scenari üåê
##### Scenario 1, router con buffer illimitato üîµ
Abbiamo due host (A e B) che inviano ciascuno dei dati verso una destinazione passando per lo stesso router centrale
- ogni host invia ad una velocit√† $\lambda_{in}$ (byte/s)
- il router ha una sola uscite e pu√≤ spedire massimo a $R$ byte/s
- i dati dei due host si devono dividere quella capacit√† (quindi ognuno riceve $R/2$)
- in questo scenario semplificato, il buffer del router ha capacit√† infinita (non pu√≤ perdere pacchetti)
![[Pasted image 20250410181354.png]]

üìà **Cosa succede al throughput?**
‚û§ **Fase 1: invio ‚â§ R/2**
- Se A e B inviano ciascuno a meno di $R/2$, tutto viene inviato correttamente (se li sommo arriver√≤ $\le R$)

‚û§ **Fase 2: invio > R/2**
- Il router non pu√≤ trasmettere a pi√π di $R$, quindi i pacchetti vengono messi in coda nel router
	- e dato che il buffer √® illimitato, il **ritardo medio diventa altissimo** (tende all'infinito) e i pacchetti non vengono persi

![[Pasted image 20250410181404.png]]

##### Scenario 2, router con buffer limitato üü¢
Stessa situazione di prima ma con un buffer limitato, quindi ora i pacchetti vanno scartati quando il buffer √® pieno.

Supponiamo che la connessione sia affidabile, quindi quando un pacchetto viene scartato, il mittente lo ritrasmette.

Teniamo in considerazione due variabili
- `Œªin` = velocit√† con cui l‚Äôhost **scrive dati originali** nella socket.
- `Œª‚Äôin` = **tasso effettivo di trasmissione**, che include:
    - dati originali + **ritrasmissioni** ‚Üí chiamato anche **carico offerto** alla rete.
###### Abbiamo 3 casi pratici
üü¢ **Caso ideale**: il mittente sa quando il buffer √® libero
	Il mittente sa, magicamente, quando il buffer √® libero e invia i pacchetti solo in quei momenti
		- Nessun pacchetto va perso.
		- Nessuna ritrasmissione necessaria.
	Qui abbiamo che `Œªin = Œª'in`
	‚û°Ô∏è Risultato: **prestazioni perfette**, ma poco realistico.

üü° **Caso realistico**: il mittente ritrasmette solo se √® sicuro che il pacchetto √® perso
	Qui il mittente aspetta con un **timeout "lungo"**, per essere quasi certo che il pacchetto **sia davvero andato perso** prima di ritrasmetterlo.
	Esempio
		- dati utili ricevuti a $R/3$
		- dati ritrasmessi a $R/6$
		Risultato: `Œª‚Äôin = R/2`
	‚û°Ô∏è Quindi: **una parte della capacit√† viene usata per correggere le perdite**.

üî¥ **Caso peggiore**: il mittente ritrasmette troppo presto
	Se il mittente ha un timeout troppo breve, pu√≤
		- Ritrasmettere un pacchetto **che non √® andato perso**, ma che semplicemente era in ritardo (in coda).
	Risultato
		- Il router riceve **due copie** dello stesso pacchetto.
		- Solo una sar√† utile, l‚Äôaltra √® **uno spreco di banda**.
		- Il throughput ne risente: si calcola che il rendimento **scende fino a R/4**, se ogni pacchetto viene mediamente trasmesso due volte.

![[Pasted image 20250410183743.png]]

![[Pasted image 20250410183750.png]]


##### Scenario 3: 4 mittenti, router con buffer limitati e percorsi multi-hop üü£
Immagina:
- 4 host che mandano dati (es. A ‚Üí C, D ‚Üí B, B ‚Üí D, ecc.).
- Ogni connessione passa da **due router**, tipo:  
    **A ‚Üí R1 ‚Üí R2 ‚Üí C**

![[Pasted image 20250410184703.png]]

I router R1 e R2
- Hanno **buffer limitati**,
- E possono **trasmettere al massimo R byte/s**.

üîÅ **Cosa succede quando Œªin (velocit√† di invio) √® bassa?**
Nessun problema, i pacchetti non si accodano e il throughput ($\lambda_{out}$) aumenta proporzionalmente con $\lambda_{in}$.
‚úÖ Tutto bene: **pi√π invii ‚Üí pi√π ricevi**, la rete funziona in modo efficiente.

‚ö†Ô∏è **Cosa succede quando $Œª_{in}$ √® molto alta?**
Prendiamo come esempio la connessione **A ‚Üí C** che passa per:
- R1 (primo router),
- R2 (secondo router).

1. Il traffico da A arriva a R1
	- se il traffico √®  troppo, si accorda
	- se il buffer √® pieno vengono persi i pacchetti

2. Anche altri host usano R2
	- es. B invia troppi dati e lo riempi

3. Il pacchetto di A riesce a superare R1 MA R2 √® pieno
	- il pacchetto si perde

üëâ **Il lavoro fatto da R1 per inoltrare il pacchetto viene sprecato**, perch√© quel pacchetto **viene buttato via da R2**.

üß® Cosa comporta questo?
- Anche se A continua a inviare molti dati, **pochissimi arrivano a C**.
- **Il throughput di A ‚Üí C scende**, anche fino a 0, se **R2 √® sempre occupato** con i pacchetti di altri.
![[Pasted image 20250410185420.png|center]]

Questo √® un **problema di competizione per le risorse**: il router **non distingue tra pacchetti "gi√† avanti" e pacchetti nuovi**.

‚û°Ô∏è Sarebbe meglio che il router **desse priorit√† a pacchetti ‚Äúpi√π vecchi‚Äù**, cio√® che hanno gi√† percorso parte della rete.

## Riassunto
![[Pasted image 20250410185551.png]]

### Approccio ai controlli di congestione
##### 1. Controllo di congestione end-to-end
Approccio utilizzato da TCP.

La rete non dice nulla al mittente su quanto √® congestionata e il mittente deve capirlo da solo.
###### üîé Come lo capisce?
- Se **un pacchetto viene perso** (cio√® non riceve ACK), TCP **suppone** che ci sia congestione.
- Anche se riceve **3 ACK duplicati**, lo interpreta come un segnale di congestione.

##### 2. Controllo di congestione assistito dalla rete
‚û°Ô∏è Qui, i **router aiutano** il mittente a capire se c‚Äô√® congestione.

Ci sono due modi principali:
###### a) **Chokepacket**
Un router manda **un messaggio diretto** al mittente dicendo:
> ‚Äú‚ö†Ô∏è Sono congestionato! Riduci la tua velocit√†!‚Äù
###### b) **Marcatura nei pacchetti**
Il router **non manda un messaggio a parte**, ma **marca i pacchetti** in transito.  
Il destinatario riceve il pacchetto marcato e dice al mittente:
> ‚ÄúEhi, guarda che la rete √® congestionata!‚Äù

üîÅ Questo meccanismo richiede almeno **un RTT** (round-trip time) per far arrivare il messaggio al mittente.

>[!tip] Recuppino di trasmissione dati affidabile e controllo della congestione üìäüåê üåê üîÅüì°
>- trasmissione dati affidabile
>	- Una trasmissione dati affidabile consente di ridurre la perdita üìâ e la corruzione dei pacchetti
>	- queste cose possono essere causate dalla congestione üåê
>- controllo congestione üåê
>	- Avere un controllo della congestione üìäüåê üåê ci consente di risolverla o comunque di ridurla notevolmente
>		- evita il "collasso di congestione üåê" 


## Cambiamenti del TCP üîß
Il TCP classico usava il controllo della congestione end-to-end, quello moderno invece usa segnali espliciti della rete (feedback dei routers, segnali diretti...).

#### Controllo di congestione TCP: incremento adattivo e decremento moltiplicativo AIMD
I mittenti inviano il tasso di invio finch√© non si verifica la perdita di pacchetti (congestione) e da l√¨ iniziano a diminuire la velocit√† di invio.

Dividiamo in:
###### 1. Incremento additivo AI
In questa fase non ci sono perdite (o almeno non inizialmente)
- viene aumentata la velocit√† di invio di **1 MSS ogni RTT** fino a quando non viene rilevata una perdita

In pratica stiamo parlando della grandezza della finestra di congestione (`cwnd`), ossia la quantit√† di segmenti che TCP pu√≤ inviare senza aspettare un ACK.
Pi√π `cwnd` √® grande e pi√π la rete viene sfruttata

Esempio
- Ho una MSS di 1000 byte, all'inizio¬†`cwnd=3`¬†quindi TCP pu√≤ mandare 3 segmenti da 1000 byte.¬†
- Dopo 1 RTT (tempo che passa da quando manda il pacchetto a quando riceve ACK), `cwnd` diventa 4 MSS, poi 5 ecc‚Ä¶ cio√® ogni volta manda un pacchetto in pi√π ad ogni ciclo.¬†
In pratica TCP sa che in quella "finestra" non ci sono problemi.

###### 2. Decremento moltiplicativo MD
Quando TCP capisce che c'√® congestione (buffer pieni e conseguente scarto di pacchetti) vuol dire che sta inviando troppi dati e la rete non riesce a gestirli
- TCP dimezza la dimezza di invio $$\text{cwnd} \rightarrow \frac {\text{cwnd}} 2$$il che riduce immediatamente i pacchetti "in volo" nella rete e cos√¨ i buffer possono svuotarsi e la rete ridursi

In queto grafico sopra si vede questo brusco calo di invio dovuto a quando i pacchetti iniziano ad essere troppi
![[GetImage (44).png]]

###### Esempio
![[GetImage (45).png]]Cosa succede, la finestra di congestione avanza quando riceve gli ACKs per i byte gialli (che diventano verdi).¬†
L'ultimo byte riscontrato √® `LastByteAcked`, l'ultimo inviato √®¬†`LastByteSent`¬†praticamente il primo e l'ultimo. La differenza tra `Sent` e `Acked` √® al massimo quanto la finestra di congestione.¬†

Il tasso di invio di TCP √®:
![[GetImage (46).png|center]]

>[!tip] OSSERVAZIONE SU `cwnd`
>`cwnd` indica la quantit√† di byte che TCP pu√≤ inviare prima di fermarsi e aspettare le conferme    (`ACK`).
>Qui valutiamo `cwnd` come se fosse un blocco e diciamo che "TCP invia fino a `cwnd` bytes ogni RTT secondi".

##### 1. **Due limiti da rispettare**
Quando un mittente TCP invia dati, deve **rispettare due limiti contemporaneamente**:
###### a) **`rwnd`** = _receive window_
- √à la **quantit√† di spazio libero** nel **buffer del destinatario**.
- Viene comunicata **dentro ogni ACK**.
- Serve per il **controllo di flusso** ‚Üí evita che il mittente invii pi√π dati di quanti il destinatario pu√≤ gestire.
###### b) **`cwnd`** = _congestion window_
- √à un limite **gestito dal mittente**.
- Serve per il **controllo di congestione** ‚Üí evita che il mittente invii troppi dati nella rete, saturandola.
##### 2. **Formula chiave**
Il numero di byte non ancora confermati (ossia senza `ACK`) deve stare dentro il minimo tra due limiti
```
LastByteSent ‚àí LastByteAcked ‚â§ min { rwnd, cwnd }
```

Significato:
- `LastByteSent ‚àí LastByteAcked` √® il numero di **byte ‚Äúin volo‚Äù**, cio√® ancora in attesa di conferma.
- TCP **pu√≤ inviare solo fino a min(`rwnd`, `cwnd`)** byte alla volta.


## Concetto di slow start üê¢üí®
√à la fase iniziale del protocollo della congestione TCP.
Inizialmente TCP parte piano perch√© non sa nulla della rete e quindi parte con una finestra `cwnd` "piccola" pari al MSS.
Ogni RTT, questo valore viene raddoppiato aumentando il tasso di invio in modo esponenziale.

![[GetImage (47).png|center]]

Viene definita la variabile `sstresh`, interna del mittente TCP.
Serve per decidere quando smettere di crescere in modo esponenziale (***slow start***) e passare a una crescita lenta e lineare (***congestion avoidance***).
![[GetImage (48).png|center]]

In pratica, TCP parte con 
- `sstresh` = tipo 64kb
- `cwnd` = 1 MSS
e inizia quindi in slow start.

Poi ogni volta che TCP riceve gli `ACK` aumenta `cwnd` in modo esponenziale.
Quando `cwnd` raggiunge `sstresh`, TCP entra in modalit√† **lenta e lineare e cresce di 1 MSS ogni RTT**.

Se si verifica una perdita TCP la vede come una congestione e imposta `sstresh` = $\frac {\text{cwnd}} 2$ e riparte dalla **slow start**.

### Macchina a stati che chiede all'esame
![[Pasted image 20250413125128.png]]

### TCP CUBIC üì¶üöÄ
√à un'alternativa al metodo classico AIMD pensato per utilizzare meglio la banda disponibile.

Indichiamo con $V_{max}$ il valore massimo della finestra prima della perdita di pacchetti.
Con il metodo classico, si punta ad arrivare a $V_{max}$ per poi dimezzare il valore.

Con il ***cubic*** questo ridimensionamento non √® cos√¨ drastico
- all'inizio hi una crescita molto veloce
- pian piano che mi avvicino a $V_{max}$ inizio a rallentare per sfruttare meglio la banda 

>[!tip] Oss. Il vaore di $W_{max}$ viene trovato man mano che si usa la connessione.

![[GetImage (50).png]]

Qui si vede bene come l'utilizzo di cubic migliori il tput.¬†

Il modello matematico che sta dietro sta roba √® questo:¬†
- k= istante in cui la finestra raggiunger√† di nuovo $W_{max}$¬†
    - √à una stima determinata da vari fattori¬†
- Pi√π mi allontano da K e pi√π cresce la finestra (come una funzione al cubo), pi√π mi avvicino a K e pi√π gli aumenti sono "cauti" sempre pi√π piccoli.¬†

==Ad oggi √® il pi√π diffuso per i server comuni (predefinito in Linux)==


### TCP e il collegamento "collo di bottiglia" congestionato
TCP si adatta alla congestione della rete in modo passivo, cio√® a posteriori (dopo aver rilevato una perdita).

Questo viene definito collegamento "collo di bottiglia", ossia il punto della reta dove
- pi√π dati arrivano di quanti ne possano uscire
- il router non riesce a smaltire tutto
- i pacchetti si accodano, e quando la coda si riempie -> iniziano ad essere scartati.

Il problema quindi √® che in questo modo
- RTT aumenta, perch√© i pacchetti non vengono scartati ma vengono messi il coda
- Throughput (i dati che arrivano davvero a destinazione) NON aumenta, perch√© il collo di bottiglia √® quasi saturo 
![[GetImage (51).png|center]]

E quindi
> √à **bene usare al massimo il collegamento di uscita del router** (per sfruttarlo), ma **non esagerare**perch√© altrimenti si crea:
> 	- **coda** (RTT aumenta),
> 	- **perdita di pacchetti** (TCP deve ritrasmettere ‚Üí spreco di risorse).

In pratica: ‚úÖ Usa **quasi tutta** la capacit√† del collo di bottiglia,  
‚ùå ma **non oltre**, altrimenti **i pacchetti si accumulano e si perdono**.
![[GetImage (52).png]]


## Controllo di congestione basato sul ritardo (es. TCP Vegas)
##### üîÑ Cos'√® diverso rispetto a TCP "classico" (come Reno o CUBIC)?
- **TCP Reno/CUBIC** aspetta di **vedere una perdita** prima di rallentare.
- **TCP Vegas** invece **usa il ritardo (RTT)** per **anticipare** la congestione, **prima che si perdano i pacchetti**.

##### ‚öôÔ∏è Come funziona TCP Vegas?
1. **Tiene in memoria il valore pi√π basso di RTT mai visto (RTTmin)**  
    ‚Üí cio√® quando la rete **non era congestionata**.
    
2. **Calcola il throughput massimo teorico**, che sarebbe:
	``` java
    throughput massimo = cwnd / RTTmin
	```
    
3. Poi misura il throughput reale (cio√® quanti dati stanno davvero arrivando).
    
4. **Confronta i due throughput:**
    - Se il throughput reale ‚âà quello teorico ‚Üí **rete libera**  
        ‚ûù TCP **aumenta** `cwnd`.
    - Se il throughput reale << quello teorico ‚Üí **rete congestionata (si sta formando coda)**  
        ‚ûù TCP **riduce** cwnd **prima ancora che i pacchetti vengano persi**.

##### üéØ Perch√© √® intelligente?
> Perch√© **non aspetta che succeda il disastro**, ma **interpreta i primi segnali** (come i ritardi)  
> e regola il flusso **con anticipo**.

## Controllo di congestione assistito dalla rete ‚Äì ECN (Explicit Congestion Notification)
##### ü§ù Come funziona ECN?
Di base √® **come TCP Reno**, ma con una **grande differenza**:
- **Non aspetta la perdita di pacchetti.**
- Invece, i **router avvisano direttamente** il mittente che la rete √® congestionata.

##### üß≠ Passaggi passo-passo:
###### 1. **Negoziazione**
- Quando si crea una connessione TCP, **mittente e destinatario** si dicono:  
    ‚ÄúSappiamo gestire ECN?‚Äù
- Se entrambi rispondono s√¨, allora ECN viene attivato.
###### 2. **Durante la trasmissione**
- I pacchetti viaggiano **con due bit ECN attivi** nell‚Äôintestazione IP.
	![[GetImage (53).png]]
	
- Se tutto va bene ‚Üí nessun problema.
- Se un **router vede che la coda √® piena**, **non scarta** il pacchetto, ma:
    - **marca il pacchetto** con `ECN = 11` ‚Üí cio√® ‚Äú‚ö†Ô∏è attenzione: sto per scoppiare‚Äù.
###### 3. **Il destinatario riceve il pacchetto marcato**
- Si accorge del `ECN = 11`,
- E manda un **ACK speciale** al mittente con il bit `ECE = 1`.
###### 4. **Il mittente riceve l‚ÄôACK con ECE**
- Capisce che c‚Äô√® **congestione**, e quindi:
    - **riduce la sua velocit√† di invio** (come se avesse perso un pacchetto, ma **senza perderlo** davvero).

###### ‚úÖ Vantaggi di ECN
- Si evitano **perdite di pacchetti** ‚Üí meno ritrasmissioni ‚Üí pi√π efficienza.
- Il mittente **rallenta prima del disastro** ‚Üí la rete √® pi√π stabile.
- Funziona **solo se la rete (i router)** e **gli host** supportano ECN.

![[GetImage (54).png|center]]


### TCP Fairness
Quando pi√π connessioni TCP **condividono lo stesso collegamento** (collo di bottiglia), il principio di **fairness (equit√†)** dice che:

> **Ogni connessione dovrebbe ricevere la stessa porzione di banda.**

##### üìå Se la capacit√† del link √® `R`, e ci sono `K` connessioni attive:
‚û°Ô∏è Ognuna dovrebbe avere **`R/K`** di throughput (velocit√†).
![[GetImage (55).png]]

GRAFICO
![[GetImage (56).png]]
- **Asse X** = throughput della **connessione 1**
- **Asse Y** = throughput della **connessione 2**

Ogni punto sul grafico dice:
> In questo istante, **quanto sta usando la banda ogni connessione**.

##### üîµ **Linea blu diagonale** = `tp1 + tp2 = R`
Questa linea rappresenta il punto in cui la **rete √® completamente utilizzata** (ossia uguale a `R`):
> Tutta la banda disponibile √® occupata, **ma non di pi√π**.

√à il punto in cui siamo **efficienti**: niente banda sprecata, niente coda inutile.

##### üî¥ **Punto rosso iniziale**
Qui siamo ancora all‚Äôinizio:
- Entrambe le connessioni usano poca banda,
- La rete √® **sotto-utilizzata**.

##### üìà TCP aumenta la velocit√† (fase AI: Additive Increase)
- Ogni connessione **aumenta lentamente** (`+1 MSS per RTT`),
- Si avvicinano alla linea blu,
- Ma se vanno oltre (superano `R`) si crea congestione ‚Üí **perdita** ‚Üí entra in gioco la **fase MD: Multiplicative Decrease** (tipo `cwnd = cwnd / 2`).

Questo crea un ciclo **AI/MD** ‚Üí AI (salita), MD (caduta), AI (salita)‚Ä¶  
Le frecce sul grafico mostrano che, nel tempo, il sistema **tende a stabilizzarsi sulla bisettrice**, cio√®:
> **Entrambe le connessioni usano la stessa quantit√† di banda.**

##### ‚ùó Ma‚Ä¶ funziona solo se:
1. **Gli RTT sono simili**  
    ‚ûù Chi ha RTT minore riceve ACK pi√π spesso ‚Üí cresce pi√π velocemente!
2. **Le connessioni sono stabili**  
    ‚ûù Se una √® appena partita (slow start) o si √® appena ripresa da una perdita, il bilanciamento si rovina.

##### üéß E le app che non vogliono essere fair?
- Le app **multimediali** (es. video, giochi) **odiano ritardi**,
- Usano **UDP** perch√©:
    - Non ha controllo di congestione,
    - Non rallenta mai, anche se perde pacchetti,
    - **Non rispetta la fairness** ‚Üí ‚Äúnon c‚Äô√® nessuna polizia che controlla‚Äù üòÑ

##### Come varia il Throughput TCP nel tempo?
Assumiamo che si ignori la fase di slow start e ci sia sempre qualcosa da inviare.¬†
- W √® la dimensione della finestra TCP in byte nel momento in cui avviene una perdita e oscilla tra W/2 e W. 
- In ogni RTT si mandano circa 3/4 W byte quindi il tp medio √®:
	![[GetImage (57) 1.png]]


--- 


## Evoluzione del livello di trasporto
TCP e UDP¬†sono i due protocolli storici per il trasporto in rete (usati da 40 anni), ma ne sono nate nuovi varianti per diversi scenari.
![[GetImage (58).png|center]]
In pratica TCP si adatta ad ogni situazione.

#### TCP su "long, fat pipes"¬†
Usa una versione di TCP per scenari lunghi ad alta velocit√† tipo due server molto lontani (EU-America).¬†

> Obiettivo: ottenere 10 Gbps di tp.¬†

Con una dimensione di ogni segmento TCP di 1500 byte e un RTT di 100 ms serve una finestra di congestione molto grande di W=83333‚ÄØsegmenti‚ÄØin‚ÄØvolo
![[GetImage (59).png|center]]
E un tasso di perdita di L=2‚ãÖ10‚àí10¬†

Molto difficile da ottenere, ovviamente servono particolari versioni di TCP.


## üî∑ **QUIC: Quick UDP Internet Connections**
QUIC √® un **nuovo protocollo** progettato per rendere le connessioni Internet **pi√π veloci e performanti**, soprattutto per HTTP/2 e HTTP/3.
![[GetImage (61).png|300]]![[GetImage (62).png|300]]
##### üîß Dove lavora?
- Si **appoggia a UDP**, ma **lo estende** con funzionalit√† simili a TCP:
    - Affidabilit√†,
    - Controllo di congestione,
    - Cifratura integrata.

> ‚ú® In pratica: QUIC unisce **il meglio di TCP + TLS**, ma lo fa tutto **in un colpo solo**, sopra UDP.

#### üîÑ **Perch√© usare QUIC?**
Perch√©:
- **TCP √® affidabile**, ma un po' "pesante" (es. serve fare due handshake separati: uno TCP, uno TLS).
- **UDP √® leggero**, ma **non ha affidabilit√† n√© cifratura**.

QUIC nasce per:
- Offrire **pi√π di UDP**, senza avere **tutti i vincoli di TCP**.
- Funziona **meglio con le nuove versioni di HTTP**, che usano molti **flussi paralleli**.


### ü§ú **TCP vs QUIC ‚Äì differenza chiave**
![[GetImage (63).png]]
##### ‚ö†Ô∏è Con **TCP**:
- Si fa **prima** l‚Äôhandshake TCP (SYN ‚Üí SYN-ACK ‚Üí ACK),
- Poi **l‚Äôhandshake TLS** per cifrare,
- Solo **dopo** si possono scambiare dati.
##### ‚úÖ Con **QUIC**:
- Fa **un solo handshake** in cui stabilisce:
    - La connessione,
    - La cifratura,
    - E tutto il resto.
Risultato? ‚Üí **Partenza pi√π veloce**, meno latenza iniziale.


![[GetImage (64).png]]
##### ‚ñ∂Ô∏è A sinistra: **HTTP/1.1 su TCP**
- Hai 3 richieste `HTTP GET` in parallelo.
- Ma passano tutte dentro **un unico flusso TCP**.
- Se un pacchetto si perde (errore rosso) ‚Üí **blocca anche gli altri**.
    - Questo si chiama **blocco HOL** (Head-of-Line blocking): 
	    finch√© il pacchetto perso non arriva, gli altri **restano fermi**.

##### ‚ñ∂Ô∏è A destra: **HTTP/2 su QUIC**
- Ogni richiesta ha **un flusso indipendente**.
- Se un pacchetto si perde in un flusso ‚Üí **solo quel flusso si ferma**,
    - gli altri continuano normalmente.

- Risultato: **niente HOL blocking**, tutto pi√π fluido e reattivo.