>[!lemma] Definizione: Thrashing
>Si verifica quando il processore occupa più tempo a fare operazioni di paging piuttosto che a eseguire i processi stessi.

## Allocazione globale vs Allocazione locale
Quando ho più processi che lavorano in parallelo sorge 
**ALLOCAZIONE LOCALE**
- Ogni processo ha un suo spazio dedicato in memoria, se voglio aggiungere pagine devo rimuoverne qualcuna nello stesso spazio
- tutte le pagine sono attaccate
	
	**VANTAGGI**
	- facile da implementare 
	**SVANTAGGI**
	- poco efficiente, se il set di lavoro del processo aumenta oltre la memoria prestabilita si verifica il **thrashing** OPPURE se il set di lavoro si riduce la memoria viene sprecata


**ALLOCAZIONE GLOBALE**
- Ogni processo può distribuire dinamicamente le proprie pagine su TUTTA la memoria, se voglio aggiungerne una posso toglierne un'altra da un altro processo
	
	**VANTAGGI**
	- più efficiente perché è più adattivo (posso usare dei bit di aging per monitorare la frequenza di accesso alle pagine ma il thrashing può comunque verificarsi)
	**SVANTAGGI**
	- difficile da implementare

![[Pasted image 20241205165157.png|center]]


## Allocazione proporzionale vs Allocazione equa
**ALLOCAZIONE EQUA**
- Ad ogni processo do un **`tot` di memoria prestabilita** (es. $12.416$ frame fisici li divido uniformemente per 10 processi, quindi darò ad ognuno $1.241$ frame)
	- *PROBLEMA*: non tengo conto delle esigenze del singolo processo

***ALLOCAZIONE PROPORZIONALE***
- Assegno i frame in base alle **esigenze del processo**
	- Devo però dare un limite minimo di pagine che un processo può avere
	- Gestisco dinamicamente i frame aggiornandoli in modo proporzionale in base alle esigenze del processo, e per farlo mi baso sul **Page Fault Frequency** (**PFF**)
		- se un processo ne produce **troppi**, **aumento** i frame
		- se un processo ne produce **pochi**, **diminuisco** i frame


### Relazione tra allocazione di memoria e page fault
Per evitare troppi page fault, posso aumentare il numero di pagine assegnate a un processo
Conto i page fault per secondo 
- A: **alta frequenza** di page fault -> il processo ha bisogno di **più frame**
- B: **bassa frequenza** di page fault -> il processo **ha più memoria del necessario**


### Gestione del thrashing e controllo del carico di memoria
Anche con il miglior algoritmo può verificarsi il thrashing, se i set di lavoro di tutti i processi eccedono la memoria disponibile.

Il PFF può segnalare una richiesta collettiva di più memoria senza che un processo possa cedere frame. 
#### Strategie di mitigazione
**OUT of MEMORY KILLER (OOM)**
- è un processo che termina un processo se richiede troppa memoria o è poco importante

**SWAPPING**
- lo abbiamo già visto


### Come ridurre le uccisioni dell'OOM?
Posso utilizzare lo scheduling a due livelli
- quello che sto usando in foreground lo metto in RAM
- gli altri in ROM
(es, ora sto scrivendo su Obsidian ma ho aperto anche Google NON A SCHERMO; Obsidian sta in RAM, Google in ROM).

###### La selezione dei processi da spostare considera delle caratteristiche
- sono processi CPU bound o I/O bound
- qual è la dimensione e/o frequenza di paginazione dei processi

###### Altre tecniche
- **compattare**
- **comprimere**
- **deduplicare**: se ho due processi IDENTICI ma che differiscono solo per una riga di codice, posso far puntare tutte le righe agli stessi indirizzi TRANNE quella riga di differenza (così riduco di molto i costi)

### Policy di pulizia e paging daemon
##### Policy di pulizia 
>[!bug] Aging e Frame Liberi
> Per gli algoritmi di Aging è meglio avere abbastanza frame liberi, così posso effettivamente tenere traccia dell'invecchiamento (se ho tutti i frame pieni ogni volta devo fare swap e quindi poi è un casino)

##### Paging Daemon
Il Daemon è un processo in background che ogni tanto viene risvegliato per controllare cosa sta accadendo in memoria
- se ho (es.) il 50% della memoria libera, chill
- se arrivo al 60%, PREVENTIVAMENTE faccio un page swap (prevenire > curare)

##### Scrittura in memoria non volatile
Se le pagine sono state modificate le scrivo nella memoria non volatile per non perdere informazioni

##### Clock a due lancette
- una lancetta in senso anteriore ha un paging daemon che fa quello che deve fare
- la lancetta posteriore si ritroverà ora più pagine libere, eseguendo l'algoritmo di clock


### Dimensione delle pagine e bilancio dei fattori
Un SO può decidere quando fare grandi le pagine (posso unirne due da 4kb per averne una da 8kb), però ci sono di fattori da tenere in considerazione
- **PAGINE PICCOLE**: possono essere lette più velocemente ma richiedono tabelle grandi per poterle scrivere e lo swap avviene più frequentemente
- **PAGINE GRANDI**: troppo lente da leggere me c'è oggettivamente più spazio

È sempre cosa buona e giusta avere pagine "ottimali", ossia che uniscono le due caratteristiche favorevoli per entrambi i tipi di pagine.

Una tecnica per utilizzare pagine molto grandi è la **Transparent Huge Pages** (THP).

### Come calcolare la dimensione ottimale?
**Consideriamo questi parametri**
- Dimensione del processo: `s` byte (esempio 1MB)
- Dimensione della pagina: `p` byte
- Dimensione di ogni voce nella tabella: `e` byte (es. 4 o 8 byte)

**Calcolo overhead**
- **Numero di pagine per processo**: $$\sim \frac s p $$
- **Spazio occupato nella tabella delle pagine**: $$s \times \frac e p \ \ (byte)$$
- **Memoria sprecata per frammentazione interna nell'ultima pagine**: $$\frac p 2$$Per qualsiasi processo, l'ultima pagina allocata non potrebbe essere completamente riempita.
	Es: un processo richiede $10,5$KB di memoria e le pagine sono da $4$KB, il sistema dovrà allocare 3 pagine lasciando $1,5$KB di spazio inutilizzato nell'ultima pagina.

**OVERHEAD TOTALE** $$\frac {s \times e} p \ + \ \frac p 2$$Il primo termine (tabella delle pagine) aumenta con pagine più piccole
Il secondo termine (frammentazione interna) aumenta con pagine più grandi
DEVO RIUSCIRE A BILANCIARE QUESTI DUE FATTORI.

**FORMULA PER LA DIMENSIONE IDEALE DELLE PAGINE**
Faccio la derivata della funzione di overhead rispetto a p (p sarebbe la mia x) e la eguaglio a zero $$- \frac {s \times e} {p^2} \ + \ \frac 1 2\ = \ 0$$Quindi la dimensione ideale delle pagine è $$p = \sqrt{2se}$$


### Spazi separati per istruzioni e dati
In passato alcuni sistemi avevano uno spazio di indirizzamento per le istruzioni e uno per i soli dati (per il poco spazio), oggi è uno solo.

#### Dove risulta utile la divisione?
Nei sistemi multiprogrammati, molti utenti utilizzano le stesse librerie o eseguono lo stesso programma (il concetto di "ho due codici identici che differiscono per una sola riga").
Condividere memoria quindi è efficiente.
###### TIPI DI PAGINE CONDIVISIBILI
- Pagine di sola lettura: **SI**
- Pagine dei dati: generalmente **NO**

Quindi risulta utile separare gli spazi di indirizzo in:
- **I-space**: Istruzioni
- **D-space**: Dati
>[!bug] se elimino un processo devo stare attento che altri non dipendano da esso, potrebbero avvenire diversi page fault

- se esistono delle pagine in sola lettura posso riciclarle, ad esempio
    - librerie riutilizzate
	    - quando si fa il `fork`
   
- se sono dei dati in scrittura di solito non si riciclano
    - dipende tutto dall'utilizzo che se ne fa; se due processi condividono le stesse cose anche in scrittura, appena un processo inizia a scrivere qualcosa di diverso, per evitare problemi:
        - faccio avvenire una trap e copio la pagina che è stata modificata (**copy on write**)


### Librerie condivise
Dynamic Link Libraries (**DLL**) -> risparmio di spazio perché condivido librerie comuni

>[!bug] Problema
>Per indirizzare queste librerie abbiamo bisogno di indirizzi RELATIVI e NON ASSOLUTI


---

# Dettagli implementativi

### Scenari che deve gestire il SO per la memoria virtuale
**CREAZIONE DEL PROCESSO**:
- calcolare la dimensione iniziale del programma e dei dati
- creare e inizializzare la tabella della pagine
- allocare spazio nella memoria non volatile per lo spazio
- inizializzare l'area di scambio e registrare informazioni nella tabella dei processi

**ESECUZIONE DEL PROCESSO** (quando lo decide lo scheduler):
- azzerare la MMU e, eventualmente, TLB
- caricare la tabella delle pagine rendendola attiva
- **PRE-PAGINAZIONE** (facoltativo): aggiungo delle pagine utili al processo per ridurre i page fault

#### Cosa si fa quando avviene una page fault? (lo vedremo meglio poi)
**GESTIONE**
- capire quale indirizzo virtuale ha causato il page fault
- trovare la pagina necessaria nella memoria non volatile
- scegliere un frame disponibile
- caricare la pagine nel frame e ripristinare il contatore del programma

**CHIUSURA DEL PROCESSO**
- rilascio la tabella delle pagine, le pagine in memoria e lo spazio su disco/SDD
- gestire le pagine condivise con altri processi, rilasciandole solo dopo l'ultimo utilizzo


### Page fault in 10 passi
1. L'**hardware esegue una trap nel Kernel**, salvando il PC nello stack
	- le informazioni sull'istruzione corrente sono salvate nei registri speciali della CPU

2. **Viene eseguita una routine in assembly per gestire gli interrupt**, in modo da salvare i registri e altre informazioni volatili
	- viene invocato il gestore dei page fault

3. **Si va a cercare la Pagina Virtuale mancante** da parte dell'SO
	- se non è disponibile all'interno dei registri hardware, tramite il PC si capisce quale istruzione ha causato il page fault e esegue LA SUCCESSIVA, finché non viene trovata la pagina.

4. **Viene verificata la validità di un indirizzo** 
	- se non è valido ritorno un segnale di errore o termino il processo

5. **Viene scelto il frame dove inserire la pagina**
	- se non ci sono frame liberi -> algoritmi di swapping
	- se la pagina è stata modificata viene scritta in memoria non volatile e il processo è sospeso

6. **La pagina viene caricata** dopo aver liberato il frame
	- se durante il caricamento della pagina, il processo in page fault è ancora sospeso, ne viene eseguito un altro processo utente (se disponibile).

7. **Viene aggiornata la tabella delle pagine**
	- il frame viene contrassegnato come disponibile (per essere letto ig)

8. **Viene ripristinata l'istruzione in errore**
	- il processo può essere eseguito grazie al PC messo inizialmente nello stack

9. **Viene ripreso il processo in errore**

10. **Il controllo ritorna in modalità utente per continuare l'esecuzione**


### Blocco delle pagine
>[!bug] Problema
>Situazione:
>- un processo necessita di alcuni dati, li richiede e viene messo in attesa
>- questi vengono passati nella RAM dal DMA (vedremo poi)
>- UN ALTRO PROCESSO, che è stato eseguito perché l'altro era fermo, chiama un page fault prima dello scattare del clock e i dati appena inseriti vengono rimossi (perché la pagina è giovane, non modificata, non referenziata).
>
>Quindi il processo rimane bloccato.
>
>### ***Come risolvo?***

#### Pinning delle pagine
Tramite dei bit, queste pagine di I/O vengono "pinnate" e così non possono essere rimosse.

### Spazio di swap
Si tratta di quello spazio su disco dove vengono inserite le pagine del processo che non sono riuscite ad essere inserite nella RAM.
Anche qui abbiamo una tabella che ci dice dove sono posizionate quelle pagine.

Ci sono due scenari nella gestioni di queste due realta:
- **Primo scenario**: ***RAPPORTO 1:1 tra area di swap e spazio sulla memoria principale***
	- ogni pagina ha la sua posizione specifica nello spazio di swap ed è sempre la medesima
		- semplice ma occupa molta memoria
	![[Pasted image 20241206125355.png|center]]

- **Secondo scenario**: ***Dinamico***
	- utilizzo una mappa del disco che mi dice le varie posizioni nell'area di scambio
		- più difficile ma dinamica e leggera
	![[Pasted image 20241206125538.png|center]]


---

# Segmentazione
La **segmentazione** è un metodo di gestione della memoria in cui il **programma viene diviso in parti logiche chiamate segmenti**.

📌 **Perché esiste?**  
✅ Per risolvere il problema della memoria monodimensionale (dove tutto è contiguo e può sovrapporsi).

### Memoria monodimensionale
Tutta la memoria è **unico spazio contiguo** di indirizzi, da **0 a Max**, quinsi se una parte del programma cresce troppo, può **invadere lo spazio di un’altra parte**.
- **Non c’è separazione tra codice, dati e stack**.

>[!tip]- 💡 Esempio di problema  
Un programma ha tre parti: 
>1. **Codice**  
>2. **Dati (variabili)**  
>3. **Stack (esecuzione delle funzioni)**
Se lo stack cresce troppo, può **sovrascrivere i dati o il codice**, causando errori. ❌
>
![[Pasted image 20241206141244.png|center]]

### Memoria segmentata
La soluzione è quella di avere dei **segmenti** (indirizzi virtuali multipli e indipendenti) per evitare collisioni.
Ogni segmento ha un suo spazio di indirizzi, così che questo possa crescere o diminuire durante l'esecuzione senza interferire con gli altri (maggiore flessibilità).

Per raggiungere un indirizzo in memoria si utilizza
- numero del segmento
- indirizzo nel segmento 
![[Pasted image 20241206141518.png|center]]

È molto utile soprattutto perché se modifico qualcosa, devo solo modificare il segmento in cui si trova.

Ha anche una logica molto interessante:
- posso dare dei ruoli per i segmenti 
- posso gestire l'accesso 

### Memoria segmentata vs paginata

| **Caratteristica**             | **Segmentazione**                                      | **Paginazione**                                                           |
| ------------------------------ | ------------------------------------------------------ | ------------------------------------------------------------------------- |
| **Divisone della memoria**     | Segmenti **logici** di dimensione variabile            | Pagine **fisse** di dimensione uguale                                     |
| **Visibile al programmatore?** | ✅ SÌ (rappresenta parti logiche del programma)         | ❌ NO (il programma lavora con indirizzi virtuali)                         |
| **Obiettivo principale**       | Organizzare il codice in modo logico                   | Gestire la memoria virtuale in modo efficiente                            |
| **Crescita della memoria**     | Ogni segmento può crescere **separatamente**           | Tutte le pagine sono **della stessa dimensione**                          |
| **Memoria Virtuale?**          | ❌ NO (lavora direttamente con memoria fisica)          | ✅ SÌ (usa swap e memoria virtuale)                                        |
| **Frammentazione?**            | **Frammentazione esterna** (spazi liberi tra segmenti) | **Frammentazione interna** (spazio sprecato in pagine parzialmente usate) |

![[Pasted image 20241206142608.png]]


### MULTICS: pioniere della segmentazione
**MULTICS** (**Multiplexed Information and Computing Service**) è stato un **sistema operativo pionieristico** che ha introdotto la **segmentazione con paginazione**.  
📌 È il primo sistema che **combinava segmentazione e paginazione** per gestire la memoria in modo efficiente.

Il problemi che si poneva di risolvere erano
- la frammentazione causata dalla segmentazione (da sola)
- lo spreco di parti nelle pagine (es. 4kb ma usati solo 2,5) causato dalla dimensione fissa scelta dalla paginazione 
![[Pasted image 20241206143342.png|center]]

***FUNZIONAMENTO***
MULTICS usa un **modello a due livelli** per la gestione della memoria:
	1️⃣ **Segmentazione** → Ogni programma è diviso in **segmenti logici indipendenti** (codice, dati, stack, ecc.).  
	2️⃣ **Paginazione all’interno dei segmenti** → Ogni segmento è **suddiviso in pagine** di dimensione fissa per ottimizzare la gestione della memoria.

📌 **Struttura di un indirizzo in MULTICS:**
- **Segmento**: Identifica **in quale segmento** si trova un dato.
- **Numero di pagina**: indica **la pagina** in cui si trova quel dato.
- **Offset nella pagina**: Indica **la posizione esatta all’interno della pagina**.
![[Pasted image 20241206144025.png|center]]

##### Doppia tabella
MULTICS usa **due tabelle** per la gestione della memoria:
1️⃣ **Tabella dei Segmenti** (Segment Table) → Ogni programma ha la sua tabella dei segmenti.
- Ogni **segmento ha un descrittore** che contiene:
    - **Puntatore alla tabella delle pagine** 📍
    - **Dimensione del segmento** 📏
    - **Bit di protezione** 🔒 (controlla chi può leggere/scrivere il segmento)
    - **Stato del segmento** (in memoria o su disco)

2️⃣ **Tabella delle Pagine** (Page Table), già la conosciamo.

![[Pasted image 20241206143108.png|center]]

### Conversione in un indirizzo MULTICS
***Trovare il descrittore del segmento***
- Il numero del segmento viene utilizzato per individuare il descrittore del segmento nella memoria.

***Verificare la tabella delle pagine***
- Si controlla la presenza della tabella delle pagine relativa al segmento.
- Questo passaggio è fondamentale per prevenire eventuali errori.

***Esaminare la voce della pagina virtuale***
- Se la pagina non è in memoria: si verifica un page fault, e il sistema dovrà caricare la pagina dalla memoria secondaria.
- Se la pagina è in memoria: dalla voce della tabella delle pagine viene estratto l'indirizzo fisico della pagina nella memoria principale.

***Calcolare l’indirizzo fisico***
- L'indirizzo fisico nella memoria principale viene calcolato aggiungendo l'offset fornito all'indirizzo iniziale della pagina.

***Accedere alla memoria***
- Avviene l'operazione desiderata (lettura o scrittura) sulla posizione della memoria principale corrispondente.


### Ottimizzare le prestazioni in MULTICS
Per ottimizzare le prestazioni si utilizzava un TLB personalizzata

---

# Comando free
con `-h` li vediamo convertiti in formati decenti ci porta a vedere le informazioni sulla memoria RAM e sullo swap.
![[Pasted image 20241206145156.png]]
![[Pasted image 20241206145245.png]]