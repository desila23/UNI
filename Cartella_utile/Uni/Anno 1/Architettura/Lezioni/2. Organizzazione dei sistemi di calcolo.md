# Argomenti

- **PROCESSORI**:
    - organizzazione della CPU
    - esecuzione dell’istruzione
    - RISC vs CISC
    - principi di progettazione dei calcolatori
    - parallelismo a livello di istruzione
    - parallelismo a livello di processore
- **MEMORIA PRINCIPALE**:
    - bit
    - sistemi di numerazione
    - indirizzi di memoria
    - ordinamento dei byte
    - codici di correzione di errore
    - memoria cache

# I PROCESSORI
### CPU
- La CPU(Central Processing Unit) è il cervello del computer che, sfruttando il bus, esegue le istruzioni nei programmi della memoria principale

#### Cosa contiene la cpu?
- CU, il vigile
- ALU, serve per fare semplici calcoli e sfrutta i registri
- Registri (piccole memorie ad alta velocità)

# Nei registri della cpu abbiamo:
- **Program counter**(PC)
    - è un puntatore che punta all’indirizzo nella memoria centrale dell’istruzione successiva
- **Instruction register**(IR)
    - contiene l’istruzione che si sta eseguendo della memoria centrale

> [!info] PC e IR prendono le informazioni dalla memoria centrale

![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-15.15.17.png) 

bus è una collezione di cavi paralleli per trasferire indirizzi:
- bus dati 
- bus controllo 
- bus indirizzi

# Come è strutturata la CPU? (Von Neumann)
- la CPU è strutturata tramite gli elementi già descritti in precedenza insieme con un data path

#### Come funziona il data path?
- Ha da 1 a 32 registri
- A e B salvano le informazioni di due registri e li passano all’ALU che fa l’operazione, per poi andare in output ed essere inseriti in un registro di output apposito che può essere poi immagazzinato in un registro della CPU.

# Operazioni del data path:
- l’ALU oltre ad avere le operazioni elementari ha anche altre istruzioni:
    - **istruzione registro-memoria** (se A non è nel registro, non è mai stata usata, allora significa che bisogna caricare l’informazione all’interno del registro per poi venir usata)
    - **istruzione register-register** (se A è già nel registro non serve che venga caricato dalla memoria principale e viene direttamente utilizzato)

>[!info] L'ALU per fare delle operazioni sui dati li prende dai registri

>[!example]- Esempio
>
>![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-15.15.58.png)

# Esecuzione delle istruzioni:

### Si può chiamare anche fetch-decode-execute
La CPU esegue le istruzioni svolgendole in piccoli passi che principalmente si dividono così:

1. prelevare dalla memoria centrale l’istruzione successiva(suggerita dal PC) e viene salvata nell’IR;
2. aggiornamento del Program Counter con l’indirizzo dell’istruzione successiva;
3. capire il tipo di istruzione;
4. se l’istruzione richiede dei dati in memoria(parola) determinare dove si trova questo dato;
5. se serve mettere il dato nel registro della CPU;
6. eseguire l’istruzione;
7. tornare nel punto 1 così che si ripeta tutto;

# strategie di progettazione della CPU
### Esistono due filosofie:
- **Architetture CISC**, con una CPU che capisce delle istruzioni più complesse senza l’uso di istruzioni di base che le compongono (più efficace ma molto lenta)
- **Architettura RISC**, con una CPU che capisce poche e semplici istruzioni(più veloce infatti basta **un solo ciclo di data path**)

>[!info]- Intel a partire dal x486 fece un mix tra risc e cisc

## Se vuoi progettare la tua CPU devi
- Far eseguire tutte le istruzioni direttamente dall’hardware, se hai istruzioni per le architetture CISC le dividi in piccole istruzioni primitive;
- Utilizzo del parallelismo per eseguire più istruzioni nello stesso tempo;
- Le istruzioni devono essere facili da decodificare, con istruzioni regolari, di lunghezza fissa e con poche tipologie;
- Solo le istruzioni LOAD E STORE hanno accesso alla memoria, LOAD preleva STORE salva;
- Più registri (almeno 35) = più informazioni rapide da consultare;

## PARALLELISMO
Il clock è il numero totale di cicli in un secondo, oggi abbiamo raggiunto un limite di clock, per aumentare la velocità delle istruzioni ci viene incontro il parallelismo che si divide in due tipi

- **a livello di istruzione**
    - quando si eseguono operazioni indipendenti, simultaneamente
- **a livello di processore**
    - quando più CPU lavorano per risolvere lo stesso problema

### Prefetching
I calcolatori sono stati progettati con la capacità di prendere le istruzioni in memoria prima che esse vengano eseguite nel buffer di prefetch. In pratica il Prefetching era diviso in due parti

1. prelievo dell’istruzione
2. esecuzione dell’istruzione

> [!tip] Fetch = prelievo di memoria

## Pipelining
È una strategia che divide un’istruzione in piccoli passaggi che vengono eseguite da unità hardware dedicate ![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-16.52.16-1.png) 
Il Pipeline rende la latenza più bilanciata.

### Processori con più pipeline
Con il pipeline in base a quanto parallelismo faccio ottimizzo i tempi: se ho due pipeline raddoppio la latenza di emissione.
Poi si fecero più processori con più pipeline 

![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-17.15.32.png)

# Architetture superscalari
Utilizzare più di due pipeline in parallelo comporterebbe un’aumento eccessivo dell’hardware, perciò si arrivò a una soluzione differente: **dividere lo stato 4 (di esecuzione) in istruzioni che vengono eseguite contemporaneamente**. 
Ovviamente s3 deve riuscire ad inviare contemporaneamente i dati a s4 in modo praticamente simultaneo 

![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-17.38.19.png)

## Parallelismo a livello di processore
Un aumento di processori comporta un fattore di miglioramento, seppur poco elevato, per ottenere un incremento di 50/100 bisogna progettare sistemi con molte CPU.

### Ci sono tre differenti approcci per il parallelismo a livello di processore:

### Computer con parallelismo sui dati
Funziona basandosi sull’ottimizzazione della gestione dei dati

##### Classificazione di Flynn

![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-17.59.17.png)

- **Processori SIMD**: sono costituiti da un vasto numero di processori identici che svolgono le stesse istruzioni su dati differenti (super computer vettoriali)
- **Processori vettoriali**: esegue le stesse operazioni su 2 dati differenti (registri) con un unico sommatore

### Multi processori
Segue la tecnica di inserire più CPU sincronizzati che condividono una memoria in comune.
Sono definite fortemente accoppiate (**tightly coupled**) e sono **senza memoria locale**

![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-18.11.33.png)

Sono abbastanza irrealizzabili perché collegare ogni CPU solo da una memoria condivisa è quasi impensabile, perciò vennero progettati i **multi-computer**.

### Multi-computer
Se venisse messa una memoria locale per ogni CPU verrebbero ottimizzati alcuni processi che possono svolgere singolarmente le CPU, senza dover scrivere sempre tutto nella memoria condivisa **con memoria locale**. 

![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-18.12.06.png)

# Memoria principale
- serve per memorizzare software e dati
- l’unità della memoria è il bit, una variabile che assume due stati (0 e 1)![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-18.27.10.png)

# Sistemi di enumerazione
Servono per rappresentare i numeri e possono essere scritte in diverse basi. 

> [!question]- Perché in base 16 vengono usate le lettere? 
> perché venivano usati nella macchina da scrivere

### vedi gli appunti di logica sul binario [Cap6-logica](https://likingaxis.github.io/UNI/UNI/LOGICA/PARTE2LOGICA/Cap6-logica)

![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-18.40.00.png)

## Conversioni da altro a binario
- **Base 4**: prendi le informazioni in 2 blocchi ;
- **Base 8**: dividi in 3 blocchi;
- **Base 16**: dividi in 4 blocchi.


# Indirizzi di memoria
Una predefinita quantità di bit indica un indirizzo in una cella di memoria ![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-18.47.07.png)


# Ordinamento dei byte
I byte in una parola possono essere scritti:
- da sinistra a destra, **big endian** 
- da destra verso sinistra, **little endian** ![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-18.48.33.png)


# Codici di correzione
Quando le memorie dei calcolatori commettono degli errori, per proteggersi da questi, bisogna registrarli; le memorie usano dei codici di rilevazione e/o di correzione degli errori che si aggiungono alla normale informazione.
Ad esempio abbiamo **n,m e r** dove:
- n=lunghezza della parola 
- m=bit normali 
- r=bit di controllo 
Questa si chiama ***Codeword***

>[!tip] parola = insieme di dati e informazioni in bit 


# Memorie cache
"Devo leggere i dati dalla memoria principale ma è un po' lentina, se usassi sempre la memoria principale si creerebbe del bottleneck".
Si decise di creare così una **memoria a tampone** di poche dimensioni con dei tempi di accesso veloci, dove vengono salvate le informazioni più utilizzate. 

>[!example]- ***Esempio***
>Sto facendo un ordinamento, se gli elementi me li trovo in memoria a tampone e non nella memoria principale gli step successivi saranno facilitati nel confrontare le informazioni. Quando la CPU necessità di una determinata parola la cerca prima nella cache e poi in memoria centrale


## I principi
- **Principio di località spaziale**: se viene usata un'informazione A è molto probabile che verranno utilizzate delle informazioni vicino ad A
- **Principio di località temporale**: temporalmente parlando se si stanno accedendo alle informazioni di A molto probabilmente nel corso del tempo verranno usate cose nelle zone di A

> [!example]- Esempio stupido
> 
> se stai vedendo una foto nella cartella comunioni probabilmente ne scorrerai un’altra e probabilmente rimarrai temporalmente nella cartella FOTO COMUNIONI

## Gerarchie di memoria
I processori più recenti hanno diversi livelli di memoria che hanno dei compiti 

![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-19.07.03.png)

# Tipi di memoria 
Sono banchi di diverse dimensioni che hanno un indirizzamento di memoria attraverso cui si arriva al contenuto stesso. Si dividono in due tipi:

- **SIMM**: ha una riga di connettori su un solo lato
- **DIMM**: ha due righe di connettori (doppia faccia) e sono il doppio più potenti delle SIMM ![](https://likingaxis.github.io/UNI/UNI/UTILITY/Screen-Shot-2024-03-11-at-19.23.15.png)

